{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Food Reviews\n",
    "\n",
    "Data Source:https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
    "\n",
    "This dataset consists of reviews of fine foods from Amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories.\n",
    "\n",
    "![alt text](http://nycdatascience.com/blog/wp-content/uploads/2016/04/NewCover.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data includes:\n",
    "- Reviews from Oct 1999 - Oct 2012\n",
    "- 568,454 reviews\n",
    "- 256,059 users\n",
    "- 74,258 products\n",
    "- 260 users with > 50 reviews\n",
    "\n",
    "#### Attribute Information:\n",
    "\n",
    "1. Id\n",
    "2. ProductId - unique identifier for the product\n",
    "3. UserId - unqiue identifier for the user\n",
    "4. ProfileName\n",
    "5. HelpfulnessNumerator - number of users who found the review helpful\n",
    "6. HelpfulnessDenominator - number of users who indicated whether they found the review helpful or not\n",
    "7. Score - rating between 1 and 5\n",
    "8. Time - timestamp for the review\n",
    "9. Summary - brief summary of the review\n",
    "10. Text - text of the review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](http://nycdatascience.com/blog/wp-content/uploads/2016/04/AmazonReview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Objective:- Review Polarity\n",
    "Given a review, determine the review is positive or neagative\n",
    "\n",
    "#### 1.Naive Way\n",
    "Naive way to do this will be the to say Score with 1 & 2 -> Negative and 4 & 5 -> positive\n",
    "and review with score 3 is ignored and we consider it as neutral\n",
    "\n",
    "#### 2. Using text review to decide the polarity\n",
    "Take the summary and text of review and analyze it using NLP whether the customer feedback/review is positive or negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3 as sql\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "\n",
    "\n",
    "%matplotlib inline \n",
    "# sets the backend of matplotlib to the 'inline' backend:\n",
    "#With this backend, the output of plotting commands is displayed inline within frontends like the Jupyter notebook,\n",
    "#directly below the code cell that produced it. The resulting plots will then also be stored in the notebook document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Let's do the EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using sqlite3 to retrieve data from sqlite file\n",
    "con = sql.connect(\"database.sqlite\")#Connection object that represents the database\n",
    "\n",
    "#Using pandas functions to query from sql table\n",
    "df = pd.read_sql_query(\"\"\"\n",
    "SELECT * FROM Reviews \n",
    "\"\"\",con)\n",
    "\n",
    "#Reviews is the name of the table given\n",
    "#Taking only the data where score != 3 as score 3 will be neutral and it won't help us much\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>568454.000000</td>\n",
       "      <td>568454.000000</td>\n",
       "      <td>568454.00000</td>\n",
       "      <td>568454.000000</td>\n",
       "      <td>5.684540e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>284227.500000</td>\n",
       "      <td>1.743817</td>\n",
       "      <td>2.22881</td>\n",
       "      <td>4.183199</td>\n",
       "      <td>1.296257e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>164098.679298</td>\n",
       "      <td>7.636513</td>\n",
       "      <td>8.28974</td>\n",
       "      <td>1.310436</td>\n",
       "      <td>4.804331e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.393408e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>142114.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.271290e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>284227.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.311120e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>426340.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.332720e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>568454.000000</td>\n",
       "      <td>866.000000</td>\n",
       "      <td>923.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.351210e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id  HelpfulnessNumerator  HelpfulnessDenominator  \\\n",
       "count  568454.000000         568454.000000            568454.00000   \n",
       "mean   284227.500000              1.743817                 2.22881   \n",
       "std    164098.679298              7.636513                 8.28974   \n",
       "min         1.000000              0.000000                 0.00000   \n",
       "25%    142114.250000              0.000000                 0.00000   \n",
       "50%    284227.500000              0.000000                 1.00000   \n",
       "75%    426340.750000              2.000000                 2.00000   \n",
       "max    568454.000000            866.000000               923.00000   \n",
       "\n",
       "               Score          Time  \n",
       "count  568454.000000  5.684540e+05  \n",
       "mean        4.183199  1.296257e+09  \n",
       "std         1.310436  4.804331e+07  \n",
       "min         1.000000  9.393408e+08  \n",
       "25%         4.000000  1.271290e+09  \n",
       "50%         5.000000  1.311120e+09  \n",
       "75%         5.000000  1.332720e+09  \n",
       "max         5.000000  1.351210e+09  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568454"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df['Score'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sns.FacetGrid(df).\\\n",
    "# map(plt.hist,bins=df['Score'])\n",
    "# # plt.plot(df['Score'].value_counts())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAEFCAYAAAAhTRZvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XtwnNd53/Hv3gEQCxIEQfBOipR0\nJOpGW44l240lRxfXaS5txvE4iV3HnjTjNpnYf7nj1G4n00xtN4nb6dUZu3bi1HYa3y/T+iaJli3L\nsmWKImVJRyQhkgJAgiAA4r73t3+8+y4W5AK7ALHv+y729/mH2gsWB2dWzz77nHOeN+I4DiIiEk7R\noAcgIiLLU5AWEQkxBWkRkRBTkBYRCTEFaRGREIuv9wuOjc34tl2kt7eLycl5v35dy9C81KZ5qU3z\nsjw/56a/Px2pdX9LZ9LxeCzoIYSS5qU2zUttmpflhWFuWjpIi4hsdArSIiIhpiAtIhJiCtIiIiGm\nIC0iEmIK0iIiIaYgLSISYut+mEVEpNU5jkM2Xwx6GIAyaRGRaxx76TJ/9J8e5+WRqaCHoiAtInK1\nobFZHAcFaRGRMFrIFgCYms0FPBIFaRGRaywG6WzAI1GQFhG5xkLOXTRUJi0iEkIZL5OeUyYtIhI6\nCzk3SE8rkxYRCZ9MtlzuUCYtIhI+81o4FBEJr0y53LGQLZIvBHvyUEFaRKRKyXEq5Q6Amfl8gKNR\nkBYRWSKbK1J9NW0FaRGREMnklpY3ZuaD3eGhIC0iUsU7bRiLRgCYVpAWEQkPL0hv29wBqNwhIhIq\n3kGW/t5OQEFaRCRUvJ0d27d4QVrlDhGR0PDKHdt7uwBl0iIioeJ1wOvrSRGLRpRJi4iEidcBrysV\np2dTUpm0iEiYeH07OlJxNnenmFlQJi0iEhpe347Ocibt9u8oBTYeBWkRkSoL5d0dnckYW7pTAMwu\nBFfyUJAWEani7ZPuSMXp6U4CMD0XXMlDQVpEpEomWyQaiZCMR9lczqSDrEsrSIuIVFnIFehMxYhE\nImze5GbSQe7wiDfyJGPMduDnwEPW2hebOyQRkeAsZAt0ptzQ2ONl0gEG6bqZtDEmAfw1sND84YiI\nBGshW6Qj6QbpLZUgHVy5o5FM+i+BTwAfbOQFe3u7iMdj1zWo1ejvT/v2u1qJ5qU2zUttmheX4zhk\ncgV6upP096fJlGYAyJeCm6MVg7Qx5veBMWvtd4wxDQXpycn59RhXQ/r704yNzfj2+1qF5qU2zUtt\nmpdFmVwBx4F4NMLY2Exl4XBsYq7pc7Tch0C9csd7gIeMMUeBI8BnjTE71ndoIiLh4O2R7kjGlvyb\nC/Awy4qZtLX2jd5/lwP1e621F5s9KBGRIFSfNgRIxN08Np8P7orh2oInIlLm9e3wgnQkEiERj5Iv\nhjSTrmatvb+J4xARCVym6ki4JxGLqneHiEgYLFR1wPMkEtFAa9IK0iIiZV7fjs5kVZBWJi0iEg6V\nckeqqtwRV5AWEQmF6g54nmQ8piAtIhIGC1WXzvIokxYRCYmrD7OAG6RLjkMhoG14CtIiImVXH2aB\nqgMtAWXTCtIiImWLl86qEaSVSYuIBGshVyASgWRiMTQmK0fDFaRFRAKVyRboTMaJRCKV+5RJi4iE\nRCZXJJVc2g8/EXNvqyYtIhKwfLFUyZw9iXLpI1cIphOegrSISFmhUCNIx6KVx4KgIC0iUpYvlCpB\n2ZOsZNIK0iIigXEcxw3Sy2TSqkmLiASoWHJw4NogrcMsIiLB84Lw1eWORNy7zqEWDkVEAlMJ0omr\ntuDFtXAoIhK45TLppModIiLB804ULleT1u4OEZEAVTJpLRyKiITP8kFax8JFRAKXL+/euHZ3hzJp\nEZHALZdJVxYOi9qCJyISmHo1aS0ciogEaLndHXGVO0REgqd90iIiIaYteCIiIbYYpJceC49Fo0Qj\nEQVpEZEgLVeTBvfqLArSIiIBWq7cAW6dWl3wREQCtFKQTiqTFhEJ1nK7O7z7FKRFRAK0Yk06riAt\nIhKoSu+OmkE6VgniflOQFhGhzsJhOZN2HMfvYRGv9wRjTAz4JGCAIvBua+2ZZg9MRMRPKy4cepfQ\nKpau2UfdbI1k0r8OYK19A/BvgY83dUQiIgFYceEwwFOHdYO0tfZrwB+Wb+4HRps6IhGRAHgBOL5M\nuQOC6YRXt9wBYK0tGGP+FvhnwFtXem5vbxdxH78O9PenfftdrUTzUpvmpTbNCxCJkIhHGdjes+Tu\n/v406e4UAOmeTvr7Nvk6rIaCNIC19l3GmH8NPGWMOWytnav1vMnJ+XUbXD39/WnGxmZ8+32tQvNS\nm+alNs2Laz6TJx6LLpkLb26K5Qz64qUZYqXmZNPLfVDWLXcYY95pjPlg+eY8UMJdQBQR2TDyhVLN\nRUNYrFMXQlru+ArwGWPM40ACeL+1NtPcYYmI+CtfKNVcNAT3WLj3HL/VDdLlssbbfBiLiEhg8sUS\nXanaIdEL3kE0WdJhFhER6pQ7AsykFaRFRGisJq0gLSISAMdx3NOEy9SkQ32YRURkoyus0AEPIFk+\n+xFEkyUFaRFpe7kV+nZU369MWkQkACs1V6q+X7s7REQC0GiQViYtIhKAxSBdu++QgrSISIBWalMK\nVQuHCtIiIv5b6fqGsNi+VEFaRCQA9WrSSS0ciogERwuHIiIhVq8mrSAtIhKgfNEtY9QrdyhIi4gE\noF65I64GSyIiwSnUCdKRSIR4LBrIhWgVpEWk7dWrSYNb8lAmLSISgEqDpcTyITERj6oLnohIEBrJ\npBPxKHntkxYR8d/iicPavTvcx1TuEBEJRL3dHd5jCtIiIgFoJEgn4zEFaRGRIDRaky6WHIolfwO1\ngrSItL16XfCqH/M7m1aQFpG2V+8wS/Vjfh9oUZAWkbbnba1buSbtPlZQkBYR8Ve+UCICxKKRZZ+T\nTLjb87J5f/dKK0iLSNvLF0sk4lEikRWCdHkPdS6vTFpExFf5QmnFUgdAMhHM1VkUpEWk7TUWpJVJ\ni4gEItdAkE4FdJ1DBWkRaXtuJr183w6AhDJpEZFg5IulFU8bQtUVw7W7Q0TEX4VGyh1eJq190iIi\n/imWShRLTuO7O5RJi4j4p1BwgJVPG8LiPmkdZhER8VGluVK9mnRA5Y74Sg8aYxLAp4EDQAr4c2vt\nN3wYl4iILxrpJQ3hXTh8BzBurf1l4C3Af2v+kERE/OM1V4o3fOIwRJk08EXgS1W3C00ci4iI77xM\nOtnwiUN/M+kVg7S1dhbAGJPGDdYfqveCvb1dxOtsCl9P/f1p335XK9G81KZ5qa2d52Uq4wbdnnRH\nzXnw7uvq7gAgEo36Ol/1MmmMMXuBrwL/w1r7+XrPn5ycX49xNaS/P83Y2Ixvv69VaF5q07zU1u7z\ncumy+7fnc4Vr5qF6bgrlBcaZuWxT5mu5wF9v4XAA+C7wx9baR9Z9VCIiAfO21HnljOXEY1Fi0Yjv\nx8LrZdJ/CvQCHzbGfLh831ustQvNHZaIiD+yOTfopuoEaXAXD8NWk34f8D6fxiIi4jsv6KYS9Y+N\nJOIxsjoWLiLin2wlSDeQScejlS17flGQFpG2tpognUrE1KpURMRPlYXDZDhr0grSItLWVlfuiJEr\nlCg5TrOHVaEgLSJtLbeq3R3uc/I+Lh4qSItIW8uuYndHEE2WFKRFpK2tqtxRafyvTFpExBeNnjis\nfo6fVwxXkBaRtpZb5cKh+zPKpEVEfJHNF0nEo0SjkbrPXewprUxaRMQX2XypoSwaqntKK5MWEfFF\nNlesZMj1pLS7Q0TEX9l8seFMOlF+XtbHckfdpv8iImFx9Pjwur/mQrZAKhGt+dq//dAtS24v7pNW\nuUNEpOkcx6FYcojHGix3BHCdQwVpEWlbhaLbg6PRIO3VrnUsXETEB951C+Ox+tvvYHGfdFaZtIhI\n8y0G6UYzae/EoTJpEZGmq5Q74g0GaW3BExHxz6rLHWqwJCLin7WXO5RJi4g03ap3d6jBkoiIfwqF\ntZU7tLtDRMQHqy13xGNRYtGI9kmLiPhhteUO8P+K4QrSItK2VptJAyTiMbLKpEVEmm+1W/DA3Sut\nTFpExAdrKXekEjEFaRERP+TXUO5IJqI6Fi4i4odKuSO+mnJHjHyhRMlxmjWsJRSkRaRtrW13h3ug\nJe/TgRYFaRFpW2vZ3VFpsuTT0XAFaRFpW4VCiUgEYtFVlDt8brKkIC0ibatQLK0qiwb/mywpSItI\n2yoUG7++ocfvJksK0iLSttxMuvFSB/jfZElBWkTa1oYpdxhj7jHGHG3yWEREfOM4zprKHal4yBYO\njTEfAD4FdDR/OCLit6dfGGVwZDroYfiuWPL2SK+u3JEIYSZ9BvitZg9ERPx3eWqBf//pp/jkN38R\n9FB85+2RTjR4EVpP0udMOl7vCdbaLxtjDjT6gr29XcTLq59+6O9P+/a7WonmpTbNy1Jf//E5SiWH\n0ckF4qkEvT3h/sKc7l6/8TlzOQA6UokVX/fq90x/3wwAyVTCl/dT3SC9WpOT8+v9ksvq708zNjbj\n2+9rFZqX2jQvS81n8nz7J2crt3/y7DCvuWV7cANqwMxsZt1ea2o26/6HU1rxda9+z2QW3J+buDK/\nru+n5QK+dneItKkfPDtCNlfkNbcOAPDS0JWAR+SvtRwJB+hIurntQraw7mOqRUFapA0ViiW+//QQ\nqUSMP3nbEeKxCKeGpoIelq8KBXfhMLbKIN3dmQBgdiG/7mOqpaFyh7X2LHBvc4ciIn45OTjO5EyW\nB+/eQ29PBwd29nBmeIqFbIHO1LpXQUNpLVdlAejuKgfpeX+CtDJpkTb0yqVZAG4/uBWAm/ZsxnFg\n8EL7bMVba7mjuyNBBJjxKZNWkBZpQxcn3AX+HX2bALhpzxYATr3SPnXptfSSBohGI2zqTDAzn2vG\nsK79fb78FhEJlQvj88RjUbaVt9zduHszQFvVpdda7gC3Lu1XTVpBWqTNOI7DxYl5Bno7iZb7KHd3\nJtjdv4nBkelK8NroKodZVplJg1uXnl3I+3IJLQVpkTZzZTZHNldkx9auJffftHsz2XyR4bG5gEbm\nr7WWOwDSnQkcB+Yzzd+GpyAt0mYW69FLg/TObW59etTHA2lBut5yB/izDU9BWqTNVIL0VZn0QK97\ne3Si3YL02sod4M82PAVpkTZzcXyZIL21E4DRyQXfxxSE6yt3JAGYWWj+Dg8FaZE2s1y5Y9vmDmLR\nSNuUO7xj3ank6hvCVcodPmTSLXu06HPffYlEKs7b7jsY9FBEWsrFiTnSXQk2dSSW3B+LRtm2uYPR\nifbIpBeyBRKx6KpblUJVuUM16dpODo7zyLEhvv3kWUYut8dKtMh6yBdKXJ7KXFPq8Axs7WJ2Ic98\nxp89wEFayBbp7FhbnpouZ9J+nDpsuSBdKJb4+0dOVW7/6MSFAEcj0louTc7jONfWoz3be9ujLl0s\nOWTzRTpTa+t9r4XDFTz2zDAXxuf5R3fsJN2V4MfPXWibzfci12u5erSnXXZ4ePXorjU2k0prC15t\nc5k8X//hy3Sm4rz1TYe4/+69TM/nOXlmPOihibQEL0jv3Lqp5uPtssPDC9Jr7fjXmYoTjUS0u+Nq\nJwfHmc8WePNr99LTleSh1+4D4IcqeYg0pLL9rl4mvcF3eFxvJh2JRNyj4Sp3LHVmyG2jeNsBt73i\nDbs2s39HmhNnxrniXQpHRJY1Mj5PLBph2+ba1/Tr6+kgHots+B0e3nHutS4cAqS7/Gmy1FJb8E4N\nXyEei7JvYPFaYK+/bQdfuHiKk4Pj/PKduwIcnYTV0ePDnDg9TjIZJxpx+N0Hb67sc20nJcdhZHyO\nHX1dyx7giEYj9G/p5FKbZNLXc4GDdGeC4bE5iqUSsWjz8t2WCdKZXIFXLs1yaPfmJfsab97r9sEd\nHJlWkJZrLGQLfOH7p8gXFheX9/Z385Z79wc4qmBMTGXI5ors3la7Hu0Z6O3iwvg8swv5DfthNn+d\n5Q5YPNAyt1CgZ1NyXcZVS8uUO14emcZxFvveenb3byIZj3JmuH2uKCGNO/bSGPlCiV97/QE+/aGH\niUUj/OT50aCHFYjh8pmCekG6sg1vA+/wWMgWgevLpLu7vKPhzS15tEyQPj3sNiO/6aogHY9FObAj\nzfDlWd+u3iut46lyQH7D7Tvo7+3kjoN9vHJpthKw2on3N+/a1r3i8wa2bvzFw+s5behZPBre3B0e\nLROkT5WD9KGrgjTAwd3u9dnOXpzxe1gSYtNzOZ4/O8mBHelK4Lnn8ACwGLzbidcnek9/vXKHl0lv\n3MVD94K7azvI4vFrr3RLBOmS43BmeJrtvZ01az+HdvUAMDjSPpf+kfp+9uIlSo7DveXADHDkxm2k\nEjGeev4ijg9X1QiT4cuzJOJR+rd0rvi8neXrHm7UbxvFkkMmt/Yj4R7v1KHKHcCFy3MsZAvX1KM9\nB3e597d7XXpobJa/+MIzPHlS+8YBnnphlAjwS7cuBulUMsarbtrG2JUML19on29epZLDhfF5dvZ1\nVS6ZtZwt3Ul6NiU5d3Fj/v+UWYedHVCVSTd5r3RLBGmvHn3jntpBujedoq8nxZmRqbbLjjzFUolP\nfet5Xjg3yX/4m5/yjSdebtu5ALg8tcDpoSnMvi30plNLHvNKHj95/mIQQwvE2JUF8oVS3UVDcA9q\nHNiRZnw6y7RPV8T203rs7AD/OuG1xBY87wrGN+6qHaTBzaZ/9uIlxqYybK/zdW4j+t7Phjg/Osud\nh/q4ODHP1374MjNzeX7v4ZuDHlogjp+6DCzNoj233bCVzlSc46cu8zsP3EQksvrLJ4XR0ePDyz52\nftT91pDNF695Xrq7g5nZTM2f++YTZ9m9Qg37/iO71zDSYK3HHmlYXDicafeFQ8dxeOHcJN2dCXat\n8Gap1KWH268ufenKAl/74SDprgR/8GuH+fj772PH1i6OHh9mcqY9T2I+W+7nctehvmsei8ei3HFw\nK5enMm3T6vbKrBtItnSn6jzT1Vc+kTg+XTt4t7L1yqQXr87S5uWOC+PzTM5kOXygl+gKGc/B3e1b\nl/6HR0+TK5T4nQduorszwebuFA+/di/FksMPnx0Jeni+y+QK2POT7N3ezdae2sef7ywH7xNt0pzr\nSvnDuuEgXZ638amNF6TXY480QDLhbuFr+5r082cnADhc7texnP0DaZKJKM+fm/BjWKExOZPlmVNj\n7N+RrtRaAe49PEBnKsbR48Nt18r1+bOTFIoOd914bRbtueNgHxHg2dOX/RtYgK7MZonHImzqbCww\ndXXE6UzFNmQmvVDu29F1nbs7IpEI6a4EU3NtXu54/uwksNhUaTmJeJTD+7dyYXx+w/cdqPajkxdw\nHLjvyK4ltdWOZJzX37aTK7O5tglEHu/vvevQtmWfk+5Kcmj3Zk4NT/nSJCdIpZLD9FyOLd2pVdXf\n+3o6mM8UNtwhsfWqSQPs255mcibLRBM/zEK9cFgolnjx/CQDvZ2VGlm1bz95dsmCR0d5c/qXfzDI\nrQd61308YVskKTluOSOZiHJPjQWy+1+9m0eODfHosWHuNtsDGKH/So7DicFxujsT3LCzZ8Xn3nmo\nj9PDUzz38jj3Ht7h0wj9NzGdoeTAlnRjpQ7P1p4OhsbmmJjOsLt/5VOKrWQ+WyAei1zXaUOP2beF\n46cvY89f4XW3N+c9FOpM+uyFGTK5IodvWDmL9ngnqYbGZps5rNB44dwkl6cyvPaWgZpZwe5tm7hl\n3xZeODfZNgtk50dnmJrNceehvrr7ge+60c20T5ze2HXpc6Pu/w/1ThperbJ4uMHq0u5pw/XJT2/Z\n5yaDL56fXJfXqyXUmfQvvHr0/saCdFdHgq09KUYn5skViiTj13fsM+y8RcE3Hlm++9+Dr9nLi+ev\n8O2fnuc9v3qrX0MLzLPlgOsF4GpXf/NyHIeujjjHTo3x6LGhukF9tcLwzctxHM5dnCEei7CrgT3S\n1SqLh9MbZ4dQoVgikyuyeZ261u3d3k1nKo49f2VdXq+WUGfSz5+dIBKBW/dvafhn9vR3U3LgwuWN\nXZeems1y7KUxdm3bVNl+WMuRm7YxsLWLJ5+7uOG34xWKJR5/doRUIlZ3DQPchZ/9A2ly+dKG7fsy\nMZNldiHPnv7uZXtIL8dbPLw8ldkwB6OGyv1Ltq3TWYpoNMLNezZz6cpC0+rSoQ3SE9MZBkemuWFn\nD10djfe03bPdrZ0NXdrYJY9vPHGWQtHhwbv3rLgYFI1EeMs9+yiWHL7/9Cs+jtB/3gfRfUd2Nbxy\nf+v+XiIReG5wfMMEomrnyh8++3ek6zyztp19m1jIFjZMucw7R3FwhcRmtUy55GFfaU42Hdpyx1ce\nH6RYcnjTq1b3lbGvJ0VnKsbQ2BylkrPuX2H9tNwJsqnZHEePD9PTlaDkOHVPkBWLJTpTMb7/8yE2\ndydJJmqXgcLw9XytSiWH//vUeWLRCA//0t6Gf667y11gHByZZmhsjr3bN84CWXWpY6VTgys5fKCX\nwZFpTg5OtPziYSZXYPjyHL3p1DWtAq6H2ed+07fnJ3ndbeu/eBjKTPr86AxPPneRvdu7V/1HRyIR\n9u9Ik80XOTm4MReEnjk1huPAq27ub+hDKBaLcsv+XvKFEr94eWPuIz/20hijE/O8/vYdyx5gWc5t\n5YXpjZZNX5nNMjOfZ/caSh2erT0d7N62iUuTCy2/tfXshRkchxXLg2uxb6CbzlSsaXXpUAbpLz52\nGgd425tuXFMmfOTGbXR1xDlxZpzLG2xl+uLEPOdHZ+nf0sG+gcYzG7N3C10dcU4OTmy4lq65fJFv\n/fgsEeAf37Nv1T/fm06xp38TY1cyG6Y9Z6nkVBZR11rq8Nx+0P0QOznY2h/wgyPTRIADdbZmrlYs\nGuWmPVsYnVxoyrpP3SBtjIkaYz5hjHnSGHPUGHPjuo+ibGouxz88dppfnJ3kthu2VjKc1UomYrzh\njh04Djxx4sKGOXF3ZniKR54eAuBu07+qgwnJRIwH7t5DMh7liZMXN0yNcXImy0c/d4zzl2a557aB\nSi/k1brzxj4iETh6bIQzLd7/peQ4PHHyAudHZ9ne28ne7WubE8/A1i76t3QyPDbHuYszLfltY3Im\ny+WpDDu3dV33ScNavN1EzTgY1cho/ynQYa19nTHmXuCvgN9c74F856fn+fIPBikUS/R0JXj7r1zf\nZ8HOvk3cur+XF85N8pUfDHJodw+7+7vpSMRIJqKAG+Dqxbnqx2fmczgADlTepo6D4/5Tvul4d+OU\nn+hQfn75uZX7qt7sjnPtcyZnMhSKDpPTWUbG5zg/6jZtf+ORXWzv7Vr1nPSmU7zp1bv53s+G+P7T\nQwz0dnJwVw893Uk6k/HK6rQX/COR8ixFIuV/3duLf/vimMs3qf7/t3ou3MedJXO35O+tNy9Xzc14\neWH58RMjTM3meMMdO/jnb75l1XPi2ba5kwfu3sPjx0d44uRFhsfm2NnXxdaeDuKxCNFohGjE/bf6\nPVErXnn3eVnV1UGt8t6o+pvL/7n077z68avmpfIz5RuXpxYYn8pwfnSWC+Pz9G/p4IG796zLlaxf\nddM2vvf0K/zg+Ag7+7ow+7awqSPBxHTm2vdL+Ub1e6YRjYT+TK5Qc85ryRdK5PJFXr4ww0vlRb1a\nV3ZaD/cd2cVdh/pWXWprRKTep6Ix5uPAT621f1++PWytXXaFaWxsZk0fs5/99ou8NDTFA6/ezevv\n2ElqmcWtaj8/Pb5si0VwF8yOn77M6aFpsvniWoYVKr3pFPcd2VX3ysQrtZ4EuDA+x4kz4xvi8kjR\nSIS33n+IN792b91vFvXeL+BecuuxY8NN78fQbNt7O/mVu3c3dFag3vvFc2Umy89evMSF8darTW/q\niHPHoT5u2rN5Vd9Af/uhWxgb82d7Zn9/uubAGgnSnwK+bK39f+Xb54GD1tqNdaBfRCSEGvkeNA1U\nrzxEFaBFRPzRSJB+AvhVgHJN+mRTRyQiIhWNLBx+FXjIGPNj3DWAdzd3SCIi4qlbkxYRkeCE8jCL\niIi4FKRFREJMQVpEJMRC2wWvHmPMPcDHrLX3Bz2WMDDGJIBPAweAFPDn1tpvBDqokDDGxIBPAgYo\nAu+21p4JdlThYYzZDvwceMha+2LQ4wkDY8wzgNcf4GVrbWAbJloySBtjPgC8E9gYDSjWxzuAcWvt\nO40xfcAzgIK069cBrLVvMMbcD3ycJrQ2aEXlD/e/Blr/+Ok6McZ0AIQlAWzVcscZ4LeCHkTIfBH4\ncNVtHTgqs9Z+DfjD8s39wGiAwwmbvwQ+AYwEPZAQuQvoMsZ81xjzaPl8SGBaMkhba78MrH+7qRZm\nrZ211s4YY9LAl4APBT2mMLHWFowxfwv8V9z5aXvGmN8Hxqy13wl6LCEzj/vh9WbgvcDnjDGBVR1a\nMkhLbcaYvcBjwN9Zaz8f9HjCxlr7LuBm4JPGmOvr37kxvAf3oNpR4AjwWWPM+l9apPW8BPxva61j\nrX0JGAd2BjWYlqxJy7WMMQPAd4E/ttY+EvR4wsQY805gj7X2I7hZUgl3AbGtWWvf6P13OVC/11p7\nMbgRhcZ7gDuAf2WM2QX0ABeCGoyC9Mbxp0Av8GFjjFebfou1VgtC8BXgM8aYx4EE8H5r7ca6ZI+s\np/8F/I0x5ke4ba7fE2RTOR0LFxEJMdWkRURCTEFaRCTEFKRFREJMQVpEJMQUpEVEQkxb8KQlGWPe\nCnwQ9z0cBT5rrf2LYEclsv6USUvLMcbsBv4KeNhaexfwOuDtxpjfCHZkIutPmbS0om24h1K6cDv/\nzRpj3gVkjDEP4gbwKHAO+F1gFvjPwAO4hxP+zlr7sXJHvP8IxIDngD8C/jtwe/m+j1lrv+DnHyZy\nNR1mkZZkjPmfwB/gtmR9DPg88CJwHniztfa4MeYjuN3disBDwFtxe20fBf4Mt9Xt14D91topY8xH\ngRFr7X8xxvQAPwZ+w1o76OsfJ1JFQVpaVrns8TBut7LfBP4d8HZr7auvet6XcLPnr5dvvw+3Zek3\ncLPle8r3P42bnefKP7oZ+BNr7Td9+HNEalK5Q1qOMeafAN3W2v8DfAa3L8e/wC1tOFXP2wykuXbt\nJcLie7+6t0kMeIe19lj55wflJdc7AAAAt0lEQVSAiab8ESIN0sKhtKJ54CPGmAMAxpgIbqvNnwPb\njTGHy8/7AG4/4EeBdxljYsaYLuD3cEskV3sU+Jfl19wJnAD2NfHvEKlLQVpajrX2Mdya8reMMRa3\nFl0E/g3uZcQ+a4w5ARwGPop7eagh4FncGvY3rbVfrfHSfwZ0GmOeww3YH9C1ECVoqkmLiISYMmkR\nkRBTkBYRCTEFaRGREFOQFhEJMQVpEZEQU5AWEQkxBWkRkRD7/xZdy3gXq87vAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(df['Score'],bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    363122\n",
       "4     80655\n",
       "1     52268\n",
       "3     42640\n",
       "2     29769\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using pandas functions to query from sql table\n",
    "df = pd.read_sql_query(\"\"\"\n",
    "SELECT * FROM Reviews \n",
    "WHERE Score != 3\n",
    "\"\"\",con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Naive Way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score as positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "0                     1                       1  Positive  1303862400   \n",
       "1                     0                       0  Negative  1346976000   \n",
       "2                     1                       1  Positive  1219017600   \n",
       "3                     3                       3  Negative  1307923200   \n",
       "4                     0                       0  Positive  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def polarity(x):\n",
    "    if x < 3:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "df[\"Score\"] = df[\"Score\"].map(polarity) #Map all the scores as the function polarity i.e. positive or negative\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Using Score column now we can say either a Review is positive or negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Using Text data and Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we need to perform some data cleaning and then text preprocessing and convert the texts as vectors so that we can train some model on those vectors and predict polarity of the review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Data Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    364173\n",
       "True     161641\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exist alot of duplicates wherein the different products is <b>reviewed by same user at the same time</b> <br>\n",
    "The product ID may be different but the product is similar with different variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78445</td>\n",
       "      <td>B000HDL1RQ</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138317</td>\n",
       "      <td>B000HDOPYC</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138277</td>\n",
       "      <td>B000HDOPYM</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73791</td>\n",
       "      <td>B000HDOPZG</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155049</td>\n",
       "      <td>B000PAQ75C</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id   ProductId         UserId      ProfileName  HelpfulnessNumerator  \\\n",
       "0   78445  B000HDL1RQ  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "1  138317  B000HDOPYC  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "2  138277  B000HDOPYM  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "3   73791  B000HDOPZG  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "4  155049  B000PAQ75C  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time  \\\n",
       "0                       2      5  1199577600   \n",
       "1                       2      5  1199577600   \n",
       "2                       2      5  1199577600   \n",
       "3                       2      5  1199577600   \n",
       "4                       2      5  1199577600   \n",
       "\n",
       "                             Summary  \\\n",
       "0  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "1  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "2  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "3  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "4  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "\n",
       "                                                Text  \n",
       "0  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
       "1  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
       "2  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
       "3  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
       "4  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display= pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score != 3 AND UserId=\"AR5J8UI46CURR\"\n",
    "ORDER BY ProductID\n",
    "\"\"\", con)\n",
    "display\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geeta gave the review at the same time for multiple product which is not possible ethically, the product were same but different flavours hence counted as multiple products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Deleting all the duplicates having the same userID, Profile, NameTime and Text all in the same column.\n",
    "df1 =  df.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"},keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.7 % reduction in data after deleting duplicates\n",
      "Size of data 364173  rows \n"
     ]
    }
   ],
   "source": [
    "size_diff = df1['Id'].size/df['Id'].size\n",
    "print(\"%.1f %% reduction in data after deleting duplicates\"%((1-size_diff)*100))\n",
    "print(\"Size of data\",df1['Id'].size,\" rows \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Helpfullness Numerator Greater than Helpfullness Denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data 364171  rows \n"
     ]
    }
   ],
   "source": [
    "df2 = df1[df1.HelpfulnessNumerator <= df1.HelpfulnessDenominator]\n",
    "print(\"Size of data\",df2['Id'].size,\" rows \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1] HTML Tag Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I Want This text!'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re #Regex (Regualar Expr Operations)\n",
    "#string = r\"sdfsdfd\" :- r is for raw string as Regex often uses \\ backslashes(\\w), so they are often raw strings(r’\\d’)\n",
    "\n",
    "########Function to remove html tags from data\n",
    "def striphtml(data):\n",
    "    p = re.compile('<.*?>')#Find this kind of pattern\n",
    "#     print(p.findall(data))#List of strings which follow the regex pattern\n",
    "    return p.sub('',data) #Substitute nothing at the place of strings which matched the patterns\n",
    "\n",
    "striphtml('<a href=\"foo.com\" class=\"bar\">I Want This <b>text!</b></a><>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [2] Punctuations Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fsd sdfsdfdsvv'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########Function to remove All the punctuations from the text\n",
    "def strippunc(data):\n",
    "    p = re.compile(r'[?|!|\\'|\"|#|.|,|)|(|\\|/|~|%|*]')\n",
    "    return p.sub('',data)\n",
    "strippunc(\"fsd*?~,,,( sdfsdfdsvv)#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [3] Stopwords\n",
    "Stop words usually refers to the most common words in a language are generally filtered out before or after processing of natural language data. Sometimes it is avoided to remove the stop words to support phrase search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stop = stopwords.words('english') #All the stopwords in English language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [4] Stemming\n",
    "Porter Stemmer: Most commonly used stemmer without a doubt, also one of the most gentle stemmers. Though it is also the most computationally intensive of the algorithms. It is also the oldest stemming algorithm by a large margin.\n",
    "\n",
    "SnowBall Stemmer(Porter2): Nearly universally regarded as an improvement over porter, and for good reason. Porter himself in fact admits that it is better than his original algorithm. Slightly faster computation time than Porter, with a fairly large community around it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stem/Root words of the some of the words using SnowBall Stemmer:\n",
      "tasti\n",
      "delici\n",
      "amaz\n",
      "initi\n",
      "fabul\n",
      "honda c\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snow = SnowballStemmer('english') #initialising the snowball stemmer\n",
    "print(\"Stem/Root words of the some of the words using SnowBall Stemmer:\")\n",
    "print(snow.stem('tasty'))\n",
    "print(snow.stem('delicious'))\n",
    "print(snow.stem('amazing'))\n",
    "print(snow.stem('initialize'))\n",
    "print(snow.stem('fabulous'))\n",
    "print(snow.stem('Honda City'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://image.slidesharecdn.com/l02words-150814131138-lva1-app6892/95/natural-language-processing-l02-words-26-638.jpg?cb=1439558153)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing output for one review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.\n",
      "['This', 'is', 'a', 'confection', 'that', 'has', 'been', 'around', 'a', 'few', 'centuries', 'It', 'is', 'a', 'light', 'pillowy', 'citrus', 'gelatin', 'with', 'nuts', '-', 'in', 'this', 'case', 'Filberts', 'And', 'it', 'is', 'cut', 'into', 'tiny', 'squares', 'and', 'then', 'liberally', 'coated', 'with', 'powdered', 'sugar', 'And', 'it', 'is', 'a', 'tiny', 'mouthful', 'of', 'heaven', 'Not', 'too', 'chewy', 'and', 'very', 'flavorful', 'I', 'highly', 'recommend', 'this', 'yummy', 'treat', 'If', 'you', 'are', 'familiar', 'with', 'the', 'story', 'of', 'CS', 'Lewis', 'The', 'Lion', 'The', 'Witch', 'and', 'The', 'Wardrobe', '-', 'this', 'is', 'the', 'treat', 'that', 'seduces', 'Edmund', 'into', 'selling', 'out', 'his', 'Brother', 'and', 'Sisters', 'to', 'the', 'Witch']\n",
      "================================> This\n",
      "Eliminated as it is a stopword\n",
      "================================> is\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> a\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> confection\n",
      "Selected: Stem Word-> b'confect'\n",
      "================================> that\n",
      "Eliminated as it is a stopword\n",
      "================================> has\n",
      "Eliminated as it is a stopword\n",
      "================================> been\n",
      "Eliminated as it is a stopword\n",
      "================================> around\n",
      "Selected: Stem Word-> b'around'\n",
      "================================> a\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> few\n",
      "Eliminated as it is a stopword\n",
      "================================> centuries\n",
      "Selected: Stem Word-> b'centuri'\n",
      "================================> It\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> is\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> a\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> light\n",
      "Selected: Stem Word-> b'light'\n",
      "================================> pillowy\n",
      "Selected: Stem Word-> b'pillowi'\n",
      "================================> citrus\n",
      "Selected: Stem Word-> b'citrus'\n",
      "================================> gelatin\n",
      "Selected: Stem Word-> b'gelatin'\n",
      "================================> with\n",
      "Eliminated as it is a stopword\n",
      "================================> nuts\n",
      "Selected: Stem Word-> b'nut'\n",
      "================================> -\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> in\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> this\n",
      "Eliminated as it is a stopword\n",
      "================================> case\n",
      "Selected: Stem Word-> b'case'\n",
      "================================> Filberts\n",
      "Selected: Stem Word-> b'filbert'\n",
      "================================> And\n",
      "Eliminated as it is a stopword\n",
      "================================> it\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> is\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> cut\n",
      "Selected: Stem Word-> b'cut'\n",
      "================================> into\n",
      "Eliminated as it is a stopword\n",
      "================================> tiny\n",
      "Selected: Stem Word-> b'tini'\n",
      "================================> squares\n",
      "Selected: Stem Word-> b'squar'\n",
      "================================> and\n",
      "Eliminated as it is a stopword\n",
      "================================> then\n",
      "Eliminated as it is a stopword\n",
      "================================> liberally\n",
      "Selected: Stem Word-> b'liber'\n",
      "================================> coated\n",
      "Selected: Stem Word-> b'coat'\n",
      "================================> with\n",
      "Eliminated as it is a stopword\n",
      "================================> powdered\n",
      "Selected: Stem Word-> b'powder'\n",
      "================================> sugar\n",
      "Selected: Stem Word-> b'sugar'\n",
      "================================> And\n",
      "Eliminated as it is a stopword\n",
      "================================> it\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> is\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> a\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> tiny\n",
      "Selected: Stem Word-> b'tini'\n",
      "================================> mouthful\n",
      "Selected: Stem Word-> b'mouth'\n",
      "================================> of\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> heaven\n",
      "Selected: Stem Word-> b'heaven'\n",
      "================================> Not\n",
      "Eliminated as it is a stopword\n",
      "================================> too\n",
      "Eliminated as it is a stopword\n",
      "================================> chewy\n",
      "Selected: Stem Word-> b'chewi'\n",
      "================================> and\n",
      "Eliminated as it is a stopword\n",
      "================================> very\n",
      "Eliminated as it is a stopword\n",
      "================================> flavorful\n",
      "Selected: Stem Word-> b'flavor'\n",
      "================================> I\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> highly\n",
      "Selected: Stem Word-> b'high'\n",
      "================================> recommend\n",
      "Selected: Stem Word-> b'recommend'\n",
      "================================> this\n",
      "Eliminated as it is a stopword\n",
      "================================> yummy\n",
      "Selected: Stem Word-> b'yummi'\n",
      "================================> treat\n",
      "Selected: Stem Word-> b'treat'\n",
      "================================> If\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> you\n",
      "Eliminated as it is a stopword\n",
      "================================> are\n",
      "Eliminated as it is a stopword\n",
      "================================> familiar\n",
      "Selected: Stem Word-> b'familiar'\n",
      "================================> with\n",
      "Eliminated as it is a stopword\n",
      "================================> the\n",
      "Eliminated as it is a stopword\n",
      "================================> story\n",
      "Selected: Stem Word-> b'stori'\n",
      "================================> of\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> CS\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> Lewis\n",
      "Selected: Stem Word-> b'lewi'\n",
      "================================> The\n",
      "Eliminated as it is a stopword\n",
      "================================> Lion\n",
      "Selected: Stem Word-> b'lion'\n",
      "================================> The\n",
      "Eliminated as it is a stopword\n",
      "================================> Witch\n",
      "Selected: Stem Word-> b'witch'\n",
      "================================> and\n",
      "Eliminated as it is a stopword\n",
      "================================> The\n",
      "Eliminated as it is a stopword\n",
      "================================> Wardrobe\n",
      "Selected: Stem Word-> b'wardrob'\n",
      "================================> -\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> this\n",
      "Eliminated as it is a stopword\n",
      "================================> is\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> the\n",
      "Eliminated as it is a stopword\n",
      "================================> treat\n",
      "Selected: Stem Word-> b'treat'\n",
      "================================> that\n",
      "Eliminated as it is a stopword\n",
      "================================> seduces\n",
      "Selected: Stem Word-> b'seduc'\n",
      "================================> Edmund\n",
      "Selected: Stem Word-> b'edmund'\n",
      "================================> into\n",
      "Eliminated as it is a stopword\n",
      "================================> selling\n",
      "Selected: Stem Word-> b'sell'\n",
      "================================> out\n",
      "Eliminated as it is a stopword\n",
      "================================> his\n",
      "Eliminated as it is a stopword\n",
      "================================> Brother\n",
      "Selected: Stem Word-> b'brother'\n",
      "================================> and\n",
      "Eliminated as it is a stopword\n",
      "================================> Sisters\n",
      "Selected: Stem Word-> b'sister'\n",
      "================================> to\n",
      "Eliminated as it is a numerical value or character of lenght less than 2\n",
      "================================> the\n",
      "Eliminated as it is a stopword\n",
      "================================> Witch\n",
      "Selected: Stem Word-> b'witch'\n",
      "***********************************************************************\n",
      "Finally selected words from the review:\n",
      " [b'confect around centuri light pillowi citrus gelatin nut case filbert cut tini squar liber coat powder sugar tini mouth heaven chewi flavor high recommend yummi treat familiar stori lewi lion witch wardrob treat seduc edmund sell brother sister witch']\n"
     ]
    }
   ],
   "source": [
    "str1=' '\n",
    "final_string=[]\n",
    "all_positive_words=[] # store words from +ve reviews here\n",
    "all_negative_words=[] # store words from -ve reviews here.\n",
    "s=''\n",
    "for sent in df2['Text'][2:3].values: #Running only for 2nd review\n",
    "    filtered_sentence=[]\n",
    "    print(sent) #Each review\n",
    "    sent=striphtml(sent)# remove HTMl tags\n",
    "    sent=strippunc(sent)# remove Punctuation Symbols\n",
    "    print(sent.split())\n",
    "    for w in sent.split():\n",
    "        print(\"================================>\",w)\n",
    "        if((w.isalpha()) and (len(w)>2)):#If it is a numerical value or character of lenght less than 2    \n",
    "            if(w.lower() not in stop):# If it is a stopword\n",
    "                s=(snow.stem(w.lower())).encode('utf8') #Stemming the word using SnowBall Stemmer\n",
    "                print(\"Selected: Stem Word->\",s)\n",
    "                filtered_sentence.append(s)\n",
    "            else:\n",
    "                print(\"Eliminated as it is a stopword\")\n",
    "                continue\n",
    "        else:\n",
    "            print(\"Eliminated as it is a numerical value or character of lenght less than 2\")\n",
    "            continue \n",
    "#     print(filtered_sentence)\n",
    "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
    "    \n",
    "    final_string.append(str1)\n",
    "    print(\"***********************************************************************\")\n",
    "    print(\"Finally selected words from the review:\\n\",final_string)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing on all the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed in  514.6151056289673\n"
     ]
    }
   ],
   "source": [
    "# Code takes a while to run as it needs to run on around 500k sentences.\n",
    "i=0\n",
    "str1=' '\n",
    "final_string=[]\n",
    "all_positive_words=[] # store words from +ve reviews here\n",
    "all_negative_words=[] # store words from -ve reviews here.\n",
    "s=''\n",
    "t0=time()\n",
    "for sent in df2['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "#     print(sent) #Each review\n",
    "    sent=striphtml(sent)# remove HTMl tags\n",
    "    sent=strippunc(sent)# remove Punctuation Symbols\n",
    "#     print(sent.split())\n",
    "    for w in sent.split():\n",
    "#         print(\"================================>\",w)\n",
    "        if((w.isalpha()) and (len(w)>2)):#If it is a numerical value or character of lenght less than 2    \n",
    "            if(w.lower() not in stop):# If it is a stopword\n",
    "                s=(snow.stem(w.lower())).encode('utf8') #Stemming the word using SnowBall Stemmer\n",
    "                                        #encoding as byte-string/utf-8\n",
    "#                 print(\"Selected: Stem Word->\",s)\n",
    "                filtered_sentence.append(s)\n",
    "                if (df2['Score'].values)[i] == 'Positive': \n",
    "                    all_positive_words.append(s) #list of all words used to describe positive reviews\n",
    "                if(df2['Score'].values)[i] == 'Negative':\n",
    "                    all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n",
    "            else:\n",
    "#                 print(\"Eliminated as it is a stopword\")\n",
    "                continue\n",
    "        else:\n",
    "#             print(\"Eliminated as it is a numerical value or character of lenght less than 2\")\n",
    "            continue \n",
    "#     print(filtered_sentence)\n",
    "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
    "            #encoding as byte-string/utf-8\n",
    "    \n",
    "    final_string.append(str1)\n",
    "#     print(\"***********************************************************************\")\n",
    "#     print(\"Finally selected words from the review:\\n\",final_string)\n",
    "    i+=1\n",
    "print(\"Preprocessing completed in \",time()-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code uses string as byte-string / utf-8(uses 1 byte), Python defaut stores string as Unicode / (utf16/utf32) {depends on how python was compiled}-(uses 2/4 byte) as our data is large 1 byte difference can save a lot of memory. Hence encoding the data as byte-string  \n",
    "For more info: https://stackoverflow.com/questions/10060411/byte-string-vs-unicode-string-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postive and Negative words in reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of positive words: 11531593\n",
      "No. of negative words: 2339861\n",
      "\n",
      "Most Common postive words [(b'like', 138335), (b'tast', 126024), (b'good', 109838), (b'love', 106551), (b'flavor', 106408), (b'use', 102872), (b'great', 101125), (b'one', 94396), (b'product', 88466), (b'tri', 85104)]\n",
      "\n",
      "Most Common negative words [(b'tast', 33828), (b'like', 32059), (b'product', 27411), (b'one', 20176), (b'flavor', 18898), (b'would', 17858), (b'tri', 17515), (b'use', 15148), (b'good', 14616), (b'coffe', 14291)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(\"No. of positive words:\",len(all_positive_words))\n",
    "print(\"No. of negative words:\",len(all_negative_words))\n",
    "# print(\"Sample postive words\",all_positive_words[:9])\n",
    "# print(\"Sample negative words\",all_negative_words[:9])\n",
    "positive = Counter(all_positive_words)\n",
    "print(\"\\nMost Common postive words\",positive.most_common(10))\n",
    "negative = Counter(all_negative_words)\n",
    "print(\"\\nMost Common negative words\",negative.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \"tast\" , \"like\" , \"flavor\", \"good\" and \"one\" are some of the most common words in both negative and positve reviews\n",
    "* \"good\" and \"great\" are some of the most common words in positive reviews\n",
    "* \"would\" and \"coffe\" are some of the most common words in negative reviews \n",
    "* tasty, good, etc are some of the words common in both <b>because there may be a not before it like \"not tasty\" , \"not good\"</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing our preprocessed data in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>b'bought sever vital can dog food product foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>b'product arriv label jumbo salt peanutsth pea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>b'confect around centuri light pillowi citrus ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "0                     1                       1  Positive  1303862400   \n",
       "1                     0                       0  Negative  1346976000   \n",
       "2                     1                       1  Positive  1219017600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "\n",
       "                                         CleanedText  \n",
       "0  b'bought sever vital can dog food product foun...  \n",
       "1  b'product arriv label jumbo salt peanutsth pea...  \n",
       "2  b'confect around centuri light pillowi citrus ...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding a column of CleanedText which displays the data after pre-processing of the review \n",
    "df2['CleanedText']=final_string\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Storing dataframe in sqlite3\n",
    "import sqlite3\n",
    "\n",
    "con = sqlite3.connect('final.sqlite')\n",
    "con.text_factory = str #To store the string as byte strings only\n",
    "df2.to_sql('Reviews', con,if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Key NLP Terms:\n",
    "\n",
    "## Natural Language Processing (NLP) \n",
    "A Computer Science field connected to Artificial Intelligence and Computational Linguistics which focuses on interactions between computers and human language and a machine’s ability to understand, or mimic the understanding of human language. Examples of NLP applications include Siri and Google Now.\n",
    "\n",
    "## Information Extraction \n",
    "The process of automatically extracting structured information from unstructured and/or semi-structured sources, such as text documents or web pages for example.\n",
    "\n",
    "## Sentiment Analysis \n",
    "The use of Natural Language Processing techniques to extract subjective information from a piece of text. i.e. whether an author is being subjective or objective or even positive or negative. (can also be referred to as Opinion Mining). As in this case we doing sentiment analysis of reviews of users from Amazon.\n",
    "\n",
    "## Data Corpus or Corpora \n",
    "A usually large collection of documents that can be used to infer and validate linguistic rules, as well as to do statistical analysis and hypothesis testing.eg. The Amazon Fine Food Review dataset is a corpus.\n",
    "\n",
    "## Document\n",
    "A \"document\" is a distinct text, you could treat an individual paragraph or even sentence as a \"document\".<br>\n",
    "In our case our each review is a document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words (BoW)\n",
    "\n",
    "A commonly used model in methods of Text Classification. As part of the BOW model, a piece of text (sentence or a document) is represented as a bag or multiset of words, disregarding grammar and even word order and the frequency or occurrence of each word is used as a feature for training a classifier.<br>\n",
    "OR <br>\n",
    "Simply,Converting a collection of text documents to a matrix of token counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "uni_gram = CountVectorizer() #in scikit-learn\n",
    "uni_gram_vectors = uni_gram.fit_transform(df2['Text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 115281)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_gram_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x115281 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 37 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_gram_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(uni_gram_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw earlier some of the common words occur in both positive and negative review this is potentially due to <b>not</b> is not considered before the words like tasty, good ,etc ... \n",
    "So to eliminate that we take n-grams means group of words together as one feature unlike taking one words as a feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bi-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking one words and two consecutive words together\n",
    "bi_gram = CountVectorizer(ngram_range=(1,2))\n",
    "bi_gram_vectors = bi_gram.fit_transform(df2['Text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 2910192)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_gram_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2910192 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 81 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_gram_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bi_gram_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi-gram is 25.24 times more than uni-gram\n"
     ]
    }
   ],
   "source": [
    "print(\"bi-gram is %.2f times more than uni-gram\"%((bi_gram_vectors.shape[1]/uni_gram_vectors.shape[1])))#Dividing boths columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf\n",
    "\n",
    "TFIDF = TF x IDF<br>\n",
    "<br>Term Frequency: This summarizes how often a given word appears within a document.<br>\n",
    "Inverse Document Frequency: This downscales words that appear a lot across documents in the corpus.\n",
    "<br><br>\n",
    "In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. The tf-idf value increases proportionally to the number of times a word appears in the document and is offset by the frequency of the word in the corpus, which helps to adjust for the fact that some words appear more frequently in general. It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling. Tf-idf is one of the most popular term-weighting schemes today; 83% of text-based recommender systems in digital libraries use tf-idf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/01/11181616/image-4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 110.5619204044342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "t0 = time()\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2)) #Using bi-grams\n",
    "tfidf_vec = tfidf.fit_transform(df2['Text'])\n",
    "print(\"Total time taken:\",time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 2910192)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf-idf came up with 2.9 million features for the data corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1169043)\t0.01590045941845868\n",
      "  (0, 1731751)\t0.09985422468680574\n",
      "  (0, 2512439)\t0.07753188557654225\n",
      "  (0, 139736)\t0.029784083159040773\n",
      "  (0, 2606992)\t0.01122894869868891\n",
      "  (0, 1332766)\t0.06889442639926521\n",
      "  (0, 2574871)\t0.011738051557435623\n",
      "  (0, 1747116)\t0.06482486901909602\n",
      "  (0, 2803326)\t0.07930012907000955\n",
      "  (0, 1254867)\t0.04159718513625457\n",
      "  (0, 1790983)\t0.04088056110977613\n",
      "  (0, 2502558)\t0.04642165577156382\n",
      "  (0, 2843637)\t0.015748926403967217\n",
      "  (0, 1266669)\t0.013527894532560928\n",
      "  (0, 484894)\t0.03728459784584648\n",
      "  (0, 2891706)\t0.06841001736539301\n",
      "  (0, 187768)\t0.017402249129296735\n",
      "  (0, 1257191)\t0.024894188683353104\n",
      "  (0, 991870)\t0.013280965391202574\n",
      "  (0, 1001371)\t0.027922213215414077\n",
      "  (0, 2897041)\t0.02587119691675463\n",
      "  (0, 1367600)\t0.04030270382249018\n",
      "  (0, 1710885)\t0.026574291203731594\n",
      "  (0, 1486985)\t0.04384170383146955\n",
      "  (0, 779065)\t0.04977650160980637\n",
      "  :\t:\n",
      "  (0, 1103002)\t0.10353686562804709\n",
      "  (0, 696294)\t0.10353686562804709\n",
      "  (0, 1278613)\t0.10684066264445778\n",
      "  (0, 1370940)\t0.09372669533415706\n",
      "  (0, 2063188)\t0.05989051135855274\n",
      "  (0, 2508248)\t0.06814281788976344\n",
      "  (0, 1773634)\t0.05130569646894666\n",
      "  (0, 2895652)\t0.06311779921170295\n",
      "  (0, 2466214)\t0.04798107915935203\n",
      "  (0, 1342235)\t0.04907293526468705\n",
      "  (0, 2896084)\t0.037496755264525304\n",
      "  (0, 2837249)\t0.04956288242089791\n",
      "  (0, 1672652)\t0.06964959580472331\n",
      "  (0, 2767461)\t0.03635210407843121\n",
      "  (0, 2619418)\t0.036067010006567986\n",
      "  (0, 2713922)\t0.06455025337444982\n",
      "  (0, 172577)\t0.04386287005838595\n",
      "  (0, 1819235)\t0.08045137292900377\n",
      "  (0, 2173466)\t0.06263726924876546\n",
      "  (0, 389974)\t0.05682064905134004\n",
      "  (0, 2501227)\t0.041604808622447434\n",
      "  (0, 2893220)\t0.05384874397123362\n",
      "  (0, 2530790)\t0.08768126667244673\n",
      "  (0, 1900049)\t0.10684066264445778\n",
      "  (0, 1283645)\t0.10684066264445778\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vec[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns all the features which is non-zero for a particular review from the sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are elderly',\n",
       " 'are electrolyte',\n",
       " 'are electrolytes',\n",
       " 'are elegant',\n",
       " 'are elegantly',\n",
       " 'are elevated',\n",
       " 'are eleven',\n",
       " 'are eligible',\n",
       " 'are eliminated',\n",
       " 'are eliminating']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = tfidf.get_feature_names()\n",
    "features[190000:190010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the feature of the tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>delicious mocha</td>\n",
       "      <td>0.258413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and 8oz</td>\n",
       "      <td>0.248564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stretched to</td>\n",
       "      <td>0.246668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>be stretched</td>\n",
       "      <td>0.241806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at oz</td>\n",
       "      <td>0.222133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stretched</td>\n",
       "      <td>0.214718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>best at</td>\n",
       "      <td>0.206737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8oz of</td>\n",
       "      <td>0.200252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>delicious hot</td>\n",
       "      <td>0.198591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>have delicious</td>\n",
       "      <td>0.191634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10 and</td>\n",
       "      <td>0.187661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>oz cup</td>\n",
       "      <td>0.183790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>of strong</td>\n",
       "      <td>0.182226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>to 10</td>\n",
       "      <td>0.179986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cup but</td>\n",
       "      <td>0.173172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>chocolate it</td>\n",
       "      <td>0.162737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8oz</td>\n",
       "      <td>0.160996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>is best</td>\n",
       "      <td>0.159450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>delicious</td>\n",
       "      <td>0.156376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>strong coffee</td>\n",
       "      <td>0.150015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature     tfidf\n",
       "0   delicious mocha  0.258413\n",
       "1           and 8oz  0.248564\n",
       "2      stretched to  0.246668\n",
       "3      be stretched  0.241806\n",
       "4             at oz  0.222133\n",
       "5         stretched  0.214718\n",
       "6           best at  0.206737\n",
       "7            8oz of  0.200252\n",
       "8     delicious hot  0.198591\n",
       "9    have delicious  0.191634\n",
       "10           10 and  0.187661\n",
       "11           oz cup  0.183790\n",
       "12        of strong  0.182226\n",
       "13            to 10  0.179986\n",
       "14          cup but  0.173172\n",
       "15     chocolate it  0.162737\n",
       "16              8oz  0.160996\n",
       "17          is best  0.159450\n",
       "18        delicious  0.156376\n",
       "19    strong coffee  0.150015"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top_tfidf_features(row, features, top_n=25):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    topn_ind = np.argsort(row)[::-1][:top_n]\n",
    "    #Sorting and getting the indexes using argsort and reversing to get descending wise and taking the top n values\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ind]\n",
    "    df = pd.DataFrame(top_feats,columns = ['feature', 'tfidf'])\n",
    "    return df\n",
    "top_tfidfs = top_tfidf_features(tfidf_vec[3000,:].toarray()[0],features,20)#top 20 tfidf features of 3000th review\n",
    "top_tfidfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 20 tfidf features of 3000th review in the data corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim\n",
    "Gensim is a robust open-source vector space modeling and topic modeling toolkit implemented in Python. It uses NumPy, SciPy and optionally Cython for performance. Gensim is specifically designed to handle large text collections, using data streaming and efficient incremental algorithms, which differentiates it from most other scientific software packages that only target batch and in-memory processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "[Refer Docs] :https://radimrehurek.com/gensim/models/word2vec.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Text Preprocessing \n",
    "final_string = []\n",
    "for sent in df2['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "    sent = striphtml(sent)\n",
    "    sent = strippunc(sent)\n",
    "    for word in sent.split():\n",
    "        if(word.isalpha()):\n",
    "            filtered_sentence.append(word.lower())\n",
    "    final_string.append(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_string[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# Train your own Word2Vec model using your own text corpus\n",
    "import gensim\n",
    "\n",
    "w2v_model=gensim.models.Word2Vec(final_string,min_count=5,size=50, workers=4) \n",
    "#min-count: Ignoring the words which occurs less than 5 times\n",
    "#size:Creating vectors of size 50 for each word\n",
    "#workers: Use these many worker threads to train the model (faster training with multicore machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model.save('w2vmodel')#Persist/Saving the model to a file in the disk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2vec_model = gensim.models.Word2Vec.load('w2vmodel') #Loading the model from file in the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40310"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vocub = w2v_model.wv.vocab\n",
    "len(w2v_vocub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('resemble', 0.7147347331047058),\n",
       " ('dislike', 0.6555633544921875),\n",
       " ('mean', 0.6510841846466064),\n",
       " ('prefer', 0.6370503902435303),\n",
       " ('think', 0.6140792369842529),\n",
       " ('overpower', 0.6067872047424316),\n",
       " ('overwhelm', 0.5841856002807617),\n",
       " ('icky', 0.5690346360206604),\n",
       " ('awful', 0.5675165057182312),\n",
       " ('gross', 0.5638607740402222)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('like')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tastey', 0.9034690856933594),\n",
       " ('yummy', 0.8592514395713806),\n",
       " ('satisfying', 0.8546252250671387),\n",
       " ('filling', 0.8349262475967407),\n",
       " ('delicious', 0.8262637853622437),\n",
       " ('flavorful', 0.8028091192245483),\n",
       " ('delish', 0.7671362161636353),\n",
       " ('versatile', 0.7626125812530518),\n",
       " ('addicting', 0.7550892233848572),\n",
       " ('tasteful', 0.7475717067718506)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('tasty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.8352181911468506),\n",
       " ('decent', 0.8264189958572388),\n",
       " ('terrific', 0.7949086427688599),\n",
       " ('fantastic', 0.7815598249435425),\n",
       " ('phenomenal', 0.7680084705352783),\n",
       " ('goodand', 0.7655398845672607),\n",
       " ('goodthe', 0.7516924738883972),\n",
       " ('fine', 0.733295202255249),\n",
       " ('wonderful', 0.7280316948890686),\n",
       " ('spectacular', 0.7198338508605957)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('good')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avg Word2Vec\n",
    "* One of the most naive but good ways to convert a sentence into a vector\n",
    "* Convert all the words to vectors and then just take the avg of the vectors the resulting vector represent the sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent: ['i', 'have', 'bought', 'several', 'of', 'the', 'vitality', 'canned', 'dog', 'food', 'products', 'and', 'have', 'found', 'them', 'all', 'to', 'be', 'of', 'good', 'quality', 'the', 'product', 'looks', 'more', 'like', 'a', 'stew', 'than', 'a', 'processed', 'meat', 'and', 'it', 'smells', 'better', 'my', 'labrador', 'is', 'finicky', 'and', 'she', 'appreciates', 'this', 'product', 'better', 'than', 'most']\n",
      "wvec: [-0.01090496  0.20814544 -0.4452101   2.0267358   0.02456711 -3.8158746\n",
      "  3.3060884  -1.4869989  -3.6256602   3.5086482  -1.9886972   0.8275884\n",
      "  0.9072345  -0.50866103  1.8038388   7.4530873  -2.311539    0.3759807\n",
      " -2.4663353  -1.8079076  -4.4510255  -0.11036215 -1.6080593  -0.8066635\n",
      "  2.9374328   2.308754    0.10071303 -0.61205536 -1.0900308   1.9720556\n",
      " -3.3058167   0.48497653  4.275758    1.450378    4.908048    1.1621197\n",
      " -1.4087198  -1.1557087   2.19108     6.315215    0.72961634 -0.60394746\n",
      " -2.2889216  -0.6453377   0.28944063 -1.6081058  -0.8026564   0.15771307\n",
      "  0.22835171  2.2555056 ]\n",
      "wvec: [-2.9541168  -0.63319755  1.9370779  -1.3795983  -0.24806319  2.0664444\n",
      " -1.2756627   0.27696908  0.51666784 -0.9139535  -4.982965   -0.12592773\n",
      " -3.7799351  -2.472334    1.1120634  -0.67900586 -0.74953187 -4.61634\n",
      " -1.200506   -0.31145847 -2.9117992  -1.7712429   3.420456   -6.21002\n",
      " -1.6164958   2.924109   -1.8288553  -5.4678974  -2.8443527   0.7711876\n",
      "  0.4333006   2.0916357   1.7290701   1.2887446  -0.8160222   0.8624684\n",
      "  2.4349656  -0.29391322 -3.8408968   3.6751268  -2.7663276   1.6531088\n",
      "  4.904311    3.0925412   0.83538103  2.466654   -1.4050004  -1.2240752\n",
      " -1.6062282  -1.6469269 ]\n",
      "wvec: [-2.3740747   5.721405   -0.2701272  -1.1616962   0.45505807  0.09120213\n",
      " -2.2001083  -3.1326132  -0.6519099  -3.550302   -4.0625896   1.159745\n",
      "  0.17819571  2.1721263  -1.6001931  -0.6696966   4.651798    3.3955832\n",
      " -0.03966919 -6.334523    3.0744572  -2.4566984  -1.2248948  -0.25022313\n",
      " -3.1835716  -0.88222706 -0.11383082  3.3682482  -0.30711618  1.3057021\n",
      " -1.9440165   3.1886723  -4.3512344  -0.23138805 -0.95080185 -7.4347677\n",
      " -4.0729012   0.24022381  0.8189142  -4.7088537  -0.70724577 -1.8850719\n",
      "  2.384316    0.8541225  -2.4753952  -0.24441834 -4.8663316   2.788994\n",
      " -4.066096    1.7989912 ]\n",
      "wvec: [ 1.4733261   2.8241405   0.6101132   2.0883896  -1.6562947  -0.01700195\n",
      "  4.0776334  -3.0559514  -1.3162895  -1.5843234   0.15611775  3.7182395\n",
      " -3.2012398   3.4337986   0.8514929   1.4970337   2.0569205   0.3908748\n",
      " -0.07678324  2.769923   -2.4150913   0.8821839   1.133232   -4.285443\n",
      "  3.786432    1.392637   -0.8469528  -6.841242    6.722159    1.431157\n",
      " -4.6324673   3.046554    2.6036866   0.5436597  -2.1055725   1.3772819\n",
      " -3.0816464   0.43545136  3.2651236  -4.9115033   2.959053   -1.425398\n",
      "  3.275375   -3.6008463   2.4857783   1.9802955   0.6468499   0.19010289\n",
      " -3.3298297   1.3175632 ]\n",
      "wvec: [-0.18999462  2.5400732   3.0210474   1.7066575  -0.7335574  -1.6344107\n",
      " -1.9932061   1.624618    0.04208623 -1.355262   -0.33091962 -1.5321423\n",
      " -0.09570917  3.1871674   4.923737    0.4421183  -1.5357959   0.7694191\n",
      " -2.194185   -0.7459453   1.2454568  -0.15242392  0.04958027 -0.02890005\n",
      " -2.398821   -2.8832695  -0.48202413 -3.5711706   1.5393497  -0.6073801\n",
      "  3.2047343   3.419146   -1.5933632   2.4398983  -0.40690598  0.05703558\n",
      " -2.6547763   1.5488602  -0.2835079   3.3487875   1.4851216  -0.9843847\n",
      "  0.2115579   0.1631458  -2.815395   -1.9293773  -1.8536829   1.5587493\n",
      "  3.3682075   3.5788558 ]\n",
      "wvec: [-1.3585037  -1.6533841   1.8788102  -0.38400385  2.0786176  -1.7845359\n",
      " -0.09318497  0.31650546 -0.19741544 -2.1386356  -1.1440433  -2.0445297\n",
      "  0.95114946  1.1308502   1.8909116   2.1799865  -1.6335993  -0.421792\n",
      "  0.05612076 -0.39483407 -0.0996081   2.144942    2.7689328  -0.6192006\n",
      "  3.0207996  -2.6864336   0.55480844 -1.9354261  -0.23635282  1.0868636\n",
      "  2.0952916   2.3059208  -1.8780787   1.5241797   0.53252476  0.8529749\n",
      " -1.2357243  -2.9499812   1.2121145   2.7942555   3.525725   -2.1377382\n",
      " -0.3798885  -0.8685284   1.0442215   0.9631315   2.4444957   1.4245481\n",
      " -1.3538786   1.088431  ]\n",
      "wvec: [ 2.1100817   0.09260801 -0.5732885  -1.1731704   0.53664047  0.6714072\n",
      "  0.31925657  0.47783497 -0.66790116  0.73760426 -0.3394398   0.13334115\n",
      " -0.39759192  0.5824578   0.4701684   0.11104143  0.11062205 -0.39166445\n",
      " -0.2683738   0.25146776  0.86587626 -0.25392228 -0.5220138   0.7108891\n",
      "  0.14942421  0.6151756   0.28555745 -0.7387047   0.46241692  0.12538439\n",
      "  0.8505752   0.29935855  0.29157916 -0.20203978 -0.8258495  -0.24299932\n",
      "  0.00425809 -0.49470812  0.22016296  0.45781386 -0.6067626  -0.9336471\n",
      "  0.27705204 -0.24788891  1.3517555   0.1530444   0.35977563  0.01796883\n",
      "  0.32729816  0.4907455 ]\n",
      "wvec: [ 0.37853953 -1.4124792  -0.57315713 -0.13383183  2.0927079   1.1527302\n",
      "  0.7100416  -2.7554467   0.16261232 -0.54752135 -0.7563203   0.01157417\n",
      "  0.686788   -2.5922601   2.8307326   2.4832242  -1.7571915   1.1677957\n",
      " -0.8874013   1.7033215  -1.6055108  -4.549811   -0.60997474  1.9070133\n",
      " -4.9187865  -0.18727848 -3.7460077   0.15099768  1.363851   -3.4866278\n",
      " -1.3331089   2.1631393  -1.0872697   1.6985757  -1.0102504  -0.7007686\n",
      "  0.2684794  -0.4528597   2.1743782   0.7779959  -0.8655587  -2.2702618\n",
      "  0.30032137 -0.09218542  2.005303    3.463498    3.8301425   0.29354337\n",
      "  0.9204977   3.1134734 ]\n",
      "wvec: [ 2.5173259   1.2309992  -2.1270928   0.34813577  2.5188124  -2.5536573\n",
      "  1.2751223   5.8870034  -0.26349223  5.8304973   0.21000353  0.2005632\n",
      " -2.3110766  -4.061202    1.0226626   3.0707157   4.431616    5.959809\n",
      " -2.9739106  -0.58490866  2.6952465  -0.23183589 -4.809181    3.5783784\n",
      " -1.4725823   1.6020776  -5.8177013   2.3156579  -0.9772442  -1.4445869\n",
      " -0.39792743 -1.0763876   2.07786    -0.6893489   3.774073    1.979769\n",
      "  3.4402082   0.37859717  1.487004    1.7377716  -2.7922451   3.864673\n",
      "  6.627207   -3.6578374   5.289052    4.2319536   0.3257636  -0.4174098\n",
      " -0.9708753   4.427269  ]\n",
      "wvec: [ 4.672713   -1.6700575   0.04200721 -2.4644911   1.6585069   3.1425564\n",
      "  1.1824317   0.1451207   3.8117397   6.591385   -2.686488   -1.8505527\n",
      " -1.8351943  -2.3486395   0.04233163  1.7694752  -4.2509084  -1.1012748\n",
      "  0.34806505 -0.6892767   1.354095    1.2374834  -2.1563747   5.224769\n",
      " -2.2633982  -0.36809567 -4.5433483  -2.7087626   1.0513813   1.6224385\n",
      " -5.783189   -2.346397    0.77587867 -0.33173943  3.1179068   1.9698805\n",
      "  2.7499955   1.3180455  -2.6227615  -1.5088463   0.8573602  -2.8085115\n",
      " -0.10571271 -2.58705     1.3536923   6.686193    2.6536546   4.5916944\n",
      " -6.952369    3.3234587 ]\n",
      "wvec: [-0.9908196   0.40716308 -3.4181728  -0.46123087 -0.46364102 -0.29881504\n",
      " -1.0705054  -1.4487123  -0.89305556  4.9981318   0.98420775 -2.3086321\n",
      " -2.4777305  -1.4635056  -1.0004989   5.268211   -0.30885717 -2.4932425\n",
      " -2.412896    2.1380312   4.1090226  -4.723136   -0.34108967  4.7050076\n",
      "  0.6490397  -0.6470594  -5.1105     -1.2981795  -1.7402859  -2.6507432\n",
      " -1.8237587   0.86773413  1.2223732   2.0077837   0.5578147  -2.3193712\n",
      "  2.5049102  -1.0051699  -0.7859176  -0.61242145  0.00652254 -4.866245\n",
      " -2.6215172   1.6474065  -1.120992    1.0023537   3.4209394  -1.443663\n",
      " -3.2278442  -2.2927735 ]\n",
      "wvec: [-0.24382988  1.5777347   3.393736    1.03311     1.0683632   0.6366107\n",
      "  1.8619022   0.16980585 -1.275523   -0.42655492  0.34907484 -0.99841154\n",
      "  0.9524723   3.1640394   2.679835    1.4301037  -1.4942776  -1.1331767\n",
      " -0.5463017   2.4913006   0.4061109   1.8843179   0.1822601  -1.6946021\n",
      "  1.0987306  -2.3250847   0.46623453 -1.1711255  -1.360193   -0.4841549\n",
      "  0.25537732  0.52703774  1.1763278   0.11239862  1.395774    0.9210588\n",
      "  1.6879736  -0.42109627  1.3604666   1.7332162  -0.315498   -0.6526611\n",
      " -0.1743133  -1.038567    0.38007632  1.5183262   1.7148811   0.9541158\n",
      "  0.3594434   0.11363286]\n",
      "wvec: [-2.9541168  -0.63319755  1.9370779  -1.3795983  -0.24806319  2.0664444\n",
      " -1.2756627   0.27696908  0.51666784 -0.9139535  -4.982965   -0.12592773\n",
      " -3.7799351  -2.472334    1.1120634  -0.67900586 -0.74953187 -4.61634\n",
      " -1.200506   -0.31145847 -2.9117992  -1.7712429   3.420456   -6.21002\n",
      " -1.6164958   2.924109   -1.8288553  -5.4678974  -2.8443527   0.7711876\n",
      "  0.4333006   2.0916357   1.7290701   1.2887446  -0.8160222   0.8624684\n",
      "  2.4349656  -0.29391322 -3.8408968   3.6751268  -2.7663276   1.6531088\n",
      "  4.904311    3.0925412   0.83538103  2.466654   -1.4050004  -1.2240752\n",
      " -1.6062282  -1.6469269 ]\n",
      "wvec: [-1.7601609e+00  1.8423300e+00  6.8302602e-02  7.6299900e-01\n",
      " -3.4908648e+00 -1.5811940e-01 -6.7458355e-01 -1.6283638e+00\n",
      " -3.3489821e+00 -1.7957226e+00  1.4721386e+00 -7.8318536e-02\n",
      " -2.0722811e+00  3.5274918e+00 -1.2576023e+00 -1.9779884e+00\n",
      "  7.3089994e-02  2.5844545e+00  2.2182302e+00  1.0172735e+00\n",
      "  2.4748480e+00 -3.7503502e+00 -2.4674056e+00  6.8383271e-01\n",
      " -3.2258534e+00 -1.8299321e+00  1.6191974e+00  2.5006959e+00\n",
      " -4.6313496e+00 -2.3976202e+00 -8.5094344e-04  2.3435760e+00\n",
      " -3.9418221e+00 -1.0485438e-01 -3.4902840e+00 -8.0170517e+00\n",
      " -2.0435090e+00 -3.2796321e+00  1.2611952e+00 -4.7174706e+00\n",
      "  1.6692795e+00 -4.5232350e-01  1.1486098e+00  5.4497857e-02\n",
      " -2.4732080e+00  1.9850017e-01 -2.7519169e+00  2.1304975e+00\n",
      " -7.7926526e+00  3.6955287e+00]\n",
      "wvec: [ 0.6728212  -1.6864153   0.4309303  -0.07329432  0.03743936 -1.4940089\n",
      "  0.06157277 -1.0291237  -0.5788719   2.6044643  -2.7376413  -0.8669386\n",
      " -0.53936064 -3.0623906   0.84476405  2.5767498   0.6027786  -1.8172827\n",
      " -0.37471455 -1.065113   -3.2115479   0.07352909 -1.907711    0.85672015\n",
      "  6.124435   -4.3373694  -1.7517384   1.7086625  -2.0943742   3.805009\n",
      " -1.9300992  -0.26714116  4.622568   -0.07692682  1.1705781   2.076885\n",
      " -0.04399157  1.5450892   3.9417987   1.7197045   0.7136705   1.9612715\n",
      "  0.31229016 -4.31716     2.7200038   4.9691954   0.9764701  -0.15602328\n",
      " -4.081093    0.76371497]\n",
      "wvec: [ 2.8824666   0.8530809  -1.5179778  -1.1882946   1.7380623  -3.5393338\n",
      "  2.6534004   0.9684782  -4.5176363  -1.9107306   0.71445745 -1.5800135\n",
      " -2.3559415   0.6316177   1.3427879   1.1697917  -0.26755878 -1.3479977\n",
      " -0.30109438  1.8841753  -2.0514708   2.0973492   1.4734415  -2.941016\n",
      "  0.9466635  -0.80634767 -2.5557213  -2.2662902   1.2265282  -0.08783814\n",
      " -2.06202     0.51733726 -1.491378    4.194514   -0.31312373 -2.68491\n",
      "  0.1031877  -0.29772764  0.96990705 -1.6316813   2.9928424  -0.52792346\n",
      "  2.2379258  -4.4524164  -0.06989098  3.6963294   2.7187932   1.0264711\n",
      " -0.89777136 -2.0534072 ]\n",
      "wvec: [ 1.9924916  -1.3967562   2.4662404   5.3387403  -1.8046066  -2.281155\n",
      "  3.7677329  -2.8464942  -2.2936456   3.4123642   0.42775556 -3.306789\n",
      "  1.3266033  -0.7691575   3.134847    3.7423382  -0.03056129  0.19731535\n",
      " -2.6937947  -2.6970582  -2.2287216   2.7627382  -3.107782    2.1852064\n",
      "  0.27952263 -0.8820226   2.0519047  -2.896205   -1.7430552   1.1425864\n",
      "  1.0092059  -2.5746584  -0.3210312   1.5884814  -0.33262253  1.1736203\n",
      "  0.77974606  2.0463846   5.0533695   0.18825316  0.9199974   1.508729\n",
      " -5.1055365  -2.0909111   0.5932057   0.56548494  3.287756    0.23671114\n",
      "  0.03397087 -1.640677  ]\n",
      "wvec: [ 1.3795614  -0.23867433 -0.68656605 -1.9053432  -4.573827    1.6070306\n",
      " -2.8672612  -0.12898524  4.4750037  -0.3226098   2.781158    1.5239587\n",
      " -1.0564679  -5.0085387  -1.494473    2.9185429  -4.56843     2.0213244\n",
      " -1.2818578  -7.727126   -6.1690784   2.2003589   4.136931   -3.3171706\n",
      "  4.5448985   5.967617   -6.193177    3.125326   -3.8816354  -1.5321038\n",
      "  0.8381643   3.5335705   4.1343837  -1.2403822   1.855453    4.6566043\n",
      "  4.3852506  -2.5157788  -9.341078    1.6480938  -5.092223   -3.4768744\n",
      "  2.3077033  -2.1613464  -0.02345805  0.7605944   0.49468845 -5.799796\n",
      "  5.9111857   2.7066033 ]\n",
      "wvec: [-0.18999462  2.5400732   3.0210474   1.7066575  -0.7335574  -1.6344107\n",
      " -1.9932061   1.624618    0.04208623 -1.355262   -0.33091962 -1.5321423\n",
      " -0.09570917  3.1871674   4.923737    0.4421183  -1.5357959   0.7694191\n",
      " -2.194185   -0.7459453   1.2454568  -0.15242392  0.04958027 -0.02890005\n",
      " -2.398821   -2.8832695  -0.48202413 -3.5711706   1.5393497  -0.6073801\n",
      "  3.2047343   3.419146   -1.5933632   2.4398983  -0.40690598  0.05703558\n",
      " -2.6547763   1.5488602  -0.2835079   3.3487875   1.4851216  -0.9843847\n",
      "  0.2115579   0.1631458  -2.815395   -1.9293773  -1.8536829   1.5587493\n",
      "  3.3682075   3.5788558 ]\n",
      "wvec: [ 0.44119576 -4.9105144   2.8465784   2.027608    2.5293643   0.49665648\n",
      "  1.2266479   2.2186568  -2.4529226  -5.097637   -0.26491705  1.4393662\n",
      "  2.8347747  -0.46613646 -2.5197587   0.80578196 -0.958953   -0.5819643\n",
      "  3.1677046   1.8194579  -0.6271854  -2.9488032  -3.3241727   3.081595\n",
      "  1.0516136  -1.3856417  -1.1231816  -3.0278769  -3.5418084   3.113081\n",
      " -1.603348   -0.55724317 -2.0860136   2.6519463   2.8421557   0.9483175\n",
      "  0.86036587 -1.5164411   2.393641    0.33189437  2.3935843  -2.6617393\n",
      "  2.9077153   2.3284724  -0.67295647 -0.40253872 -2.904614    2.9194736\n",
      "  6.5509915  -0.83569986]\n",
      "wvec: [ 1.8969733  -0.16313933 -1.830913   -0.6649207   1.1921506   0.84556305\n",
      "  0.96214426  0.14842905 -2.3622763  -1.7311106   1.5154468  -2.5686495\n",
      "  2.7070467   0.057618   -4.1914935   1.3669014   2.1238918   5.211887\n",
      "  0.41884428  1.0258881   0.67513186 -3.828276    2.8640258  -0.8199089\n",
      " -3.0251594  -2.0276423  -2.9715645  -3.7244418   0.82124597 -5.417432\n",
      "  0.9153681  -2.4864457   0.6710214  -1.0726272   3.8322976   0.3044072\n",
      " -0.96464    -4.1306553  -1.960578   -0.06252494 -0.09986185 -1.2994176\n",
      "  0.19120173 -1.0793443   0.6045153   2.5634935   7.0266395  -1.7593913\n",
      " -0.09310406 -3.1473362 ]\n",
      "wvec: [-1.3585037  -1.6533841   1.8788102  -0.38400385  2.0786176  -1.7845359\n",
      " -0.09318497  0.31650546 -0.19741544 -2.1386356  -1.1440433  -2.0445297\n",
      "  0.95114946  1.1308502   1.8909116   2.1799865  -1.6335993  -0.421792\n",
      "  0.05612076 -0.39483407 -0.0996081   2.144942    2.7689328  -0.6192006\n",
      "  3.0207996  -2.6864336   0.55480844 -1.9354261  -0.23635282  1.0868636\n",
      "  2.0952916   2.3059208  -1.8780787   1.5241797   0.53252476  0.8529749\n",
      " -1.2357243  -2.9499812   1.2121145   2.7942555   3.525725   -2.1377382\n",
      " -0.3798885  -0.8685284   1.0442215   0.9631315   2.4444957   1.4245481\n",
      " -1.3538786   1.088431  ]\n",
      "wvec: [ 2.5252447   1.2873851  -0.59113014 -2.316803   -3.7253559  -0.49588677\n",
      "  2.2804852  -0.5199154   2.214568    2.3650374   0.46293244 -2.120859\n",
      "  0.46006536 -0.46217093 -4.4173927   3.7432878  -1.2138268   1.7455928\n",
      "  2.261568   -1.5410765   0.20620757  0.41018295 -0.93243897  1.723567\n",
      "  0.27145508  0.08921907 -1.0818775  -2.0059109  -0.9390184   0.12065753\n",
      " -3.218579   -4.20382     4.6578894   1.0480034   3.8063378   0.02857085\n",
      "  1.1814766  -1.6025653  -3.4811935   1.8660146   2.232851   -2.9542806\n",
      " -0.8198008   1.434674    3.19652     3.19228     1.7554266  -1.2228929\n",
      " -4.4748487  -1.1523428 ]\n",
      "wvec: [ 1.4940017   4.172802   -2.4798827  -0.23902385  3.0745285  -0.8371118\n",
      " -4.508542   -0.75297636 -1.5402887  -1.879753    2.801535   -0.972071\n",
      "  4.8586698  -2.4717185   0.13159479 -2.1304734  -1.1868006   1.4541628\n",
      " -0.00646956  0.4954068   0.24813488  3.1575959  -1.811204   -0.0590502\n",
      "  0.05183076  1.5086699  -0.6039049   0.6350958   3.0307438  -0.64846325\n",
      "  1.3428173  -1.4859354  -2.9027092  -1.7717645   6.115622   -3.476543\n",
      "  3.5630429  -3.4438522  -0.7817105   0.35280675  0.6127987   0.8298113\n",
      " -0.88956475  1.9656978   1.9806714  -0.44477957  2.233266    4.0923705\n",
      " -1.9362645   1.2175831 ]\n",
      "wvec: [ 4.280067    0.44368213 -1.0533124   1.4139173   0.18362017 -1.5831289\n",
      " -0.30141655  0.46355432  4.05908    -3.2169905   1.7049968   1.8392848\n",
      " -1.6066811  -1.2530682   0.37675232  4.561452    1.3348539  -2.5167363\n",
      " -0.28524017  0.9283355  -5.5203156  -0.5657284  -1.3719127   1.3034248\n",
      "  1.422347    2.1988997   2.2792838  -3.348972   -3.491297   -2.6768503\n",
      "  1.8130311  -2.2174942   2.2993524  -4.3345804   0.42672384 -0.82413626\n",
      " -4.7556      2.9569051  -0.0432415   4.187184   -0.5726178   0.07209662\n",
      " -5.142337   -4.375798   -0.77498394  3.6543443   3.0746622   3.7026138\n",
      "  2.1698315   2.7534976 ]\n",
      "wvec: [ 0.25818774 -0.3741437   2.4150593   1.7319771   2.0716023   0.7376731\n",
      " -2.2722888   4.0686054  -2.765445   -6.1999083  -3.4662158   2.1617973\n",
      "  2.339936   -3.9482734   2.6518302  -3.778377   -0.3051682  -5.331501\n",
      "  0.7963405   0.8388573   0.5780435   1.5505087  -0.8254719  -1.1973689\n",
      " -3.3001962   1.4628918  -3.9992285   1.2039984  -3.9789326  -1.4185517\n",
      " -1.0266895  -0.6626527  -3.8317595   1.5355382  -1.7672426   0.83947885\n",
      "  1.4784346   0.92335147 -1.8791239   1.988457   -1.1257744  -3.3705626\n",
      "  2.7534306   1.063606   -0.37238967 -0.91200376 -1.301749    0.8346388\n",
      "  3.9606986  -3.7692597 ]\n",
      "wvec: [ 0.10003749  1.298291    3.386081   -0.6480232   4.365622   -0.48032343\n",
      " -2.768357    0.09017466 -2.855847    1.7516837   2.0211172  -1.7656919\n",
      "  0.47457743  1.2368053   3.8286805   2.1584537  -0.3819662  -1.0582011\n",
      "  2.3881316  -3.9100027  -2.5583944   1.0487566   2.9517844   2.0497103\n",
      "  2.048713   -1.9834436   6.3586125   0.1709362  -2.0505667   0.06587635\n",
      "  2.7095776  -1.4913471  -2.7575643   0.6693104   1.7931881   0.73906314\n",
      " -0.5770397   0.2683988  -1.5368682   2.1464515   0.9773043  -3.9027698\n",
      " -1.2966917  -0.69140476  1.2184806  -0.02121245  2.6391819  -1.019703\n",
      "  1.5541997   2.9303973 ]\n",
      "wvec: [ 0.36976802  1.343705    0.9611801   0.2531804   0.93171525  2.3336544\n",
      "  1.5708854   1.1239573  -0.12893993 -1.1352577  -0.3005632   0.6714441\n",
      "  0.7284956  -2.6126378   3.2077951   2.2949667  -2.870322    0.8677064\n",
      "  0.02953083  3.306674   -1.8731321  -1.0174539  -0.99551904  1.1241301\n",
      " -2.8067784   0.581643   -0.17318329  0.46662018  1.3601297   2.296947\n",
      " -2.0909777   0.4970063   0.4237121   0.28596863  0.17906341 -0.5104494\n",
      "  0.659218   -0.40049234  0.00936182 -1.5215113  -0.71471184 -0.3070877\n",
      " -0.165302   -0.41016355  4.3509336   1.1414347   3.8574276   0.39080027\n",
      "  0.51057357  3.121187  ]\n",
      "wvec: [ -3.7043157    3.696106     4.0369606    6.0576873   -3.826663\n",
      "  -1.4335282   -4.3638997   -2.5766518    0.25193942  -1.7498202\n",
      "  -1.9965322    3.96744     -1.8137083    1.0980552    3.9405816\n",
      "  -1.3605785    3.1416607    1.861639     2.5409667    5.304666\n",
      "   3.8468924    3.5909166   -3.2290506   -0.23934738  -2.5783758\n",
      "  -0.92609864  -4.395808     0.5905163   -1.7559699   -2.8787804\n",
      "   4.423144    -3.7398043   -6.399274     3.8774974    0.12545122\n",
      "   2.4425025    4.8004804   -0.9372288   -2.1760697    3.471988\n",
      "  -4.539907   -10.955086     3.4873233   -5.249267     1.9988984\n",
      "  -4.2567296    0.12881833  -2.270183    -2.9240263    0.39028266]\n",
      "wvec: [ 0.10003749  1.298291    3.386081   -0.6480232   4.365622   -0.48032343\n",
      " -2.768357    0.09017466 -2.855847    1.7516837   2.0211172  -1.7656919\n",
      "  0.47457743  1.2368053   3.8286805   2.1584537  -0.3819662  -1.0582011\n",
      "  2.3881316  -3.9100027  -2.5583944   1.0487566   2.9517844   2.0497103\n",
      "  2.048713   -1.9834436   6.3586125   0.1709362  -2.0505667   0.06587635\n",
      "  2.7095776  -1.4913471  -2.7575643   0.6693104   1.7931881   0.73906314\n",
      " -0.5770397   0.2683988  -1.5368682   2.1464515   0.9773043  -3.9027698\n",
      " -1.2966917  -0.69140476  1.2184806  -0.02121245  2.6391819  -1.019703\n",
      "  1.5541997   2.9303973 ]\n",
      "wvec: [-0.45197555 -3.7100258  -1.5594356   0.90471977  2.4106274   0.09550463\n",
      "  2.586081    0.68998957 -1.1213     -3.3179953   1.1532147   3.0168822\n",
      " -0.97114724 -3.8936222   0.50144136  0.6329503  -2.8052716   2.3065286\n",
      " -3.1115375   3.3837779   0.22314103 -3.734114   -0.2758805   1.6968023\n",
      "  0.9203634  -1.4919957  -2.7791698  -0.06868051  0.5069419  -4.219404\n",
      " -0.87424123 -0.28651515 -3.963261   -1.195322   -2.190663   -1.0121406\n",
      "  2.7555778   0.15357056 -1.3667822   3.504499    0.90821326 -2.0685658\n",
      "  1.4289702   0.1152956  -2.8042939   0.30804265  1.5860792  -0.14601941\n",
      " -0.47181392 -1.4801216 ]\n",
      "wvec: [ 1.6104963  -0.52518964  2.2492683   0.18458922  2.072504   -0.47279453\n",
      "  1.2371225   2.6662128   2.9210575  -0.5897246  -0.29577097 -0.4772669\n",
      "  0.42579365 -6.0813704   2.0902479   1.0012511  -5.187451    0.6583229\n",
      "  0.22263731  1.9444548   0.2747788  -1.7820755  -0.91215605  2.1953578\n",
      " -3.1903236  -4.2060595  -3.2906203  -1.7188756   1.9727869   2.4669428\n",
      " -2.446304   -0.75817007 -0.37159333  1.7044857  -0.2294991   0.31217512\n",
      "  2.19134     0.79084045 -1.3632716  -0.35193938 -0.8170845  -0.9026179\n",
      " -1.1647675  -1.1793593   2.5300064   2.3466237   4.6894445  -0.4525191\n",
      " -1.208713    5.289454  ]\n",
      "wvec: [-0.24382988  1.5777347   3.393736    1.03311     1.0683632   0.6366107\n",
      "  1.8619022   0.16980585 -1.275523   -0.42655492  0.34907484 -0.99841154\n",
      "  0.9524723   3.1640394   2.679835    1.4301037  -1.4942776  -1.1331767\n",
      " -0.5463017   2.4913006   0.4061109   1.8843179   0.1822601  -1.6946021\n",
      "  1.0987306  -2.3250847   0.46623453 -1.1711255  -1.360193   -0.4841549\n",
      "  0.25537732  0.52703774  1.1763278   0.11239862  1.395774    0.9210588\n",
      "  1.6879736  -0.42109627  1.3604666   1.7332162  -0.315498   -0.6526611\n",
      " -0.1743133  -1.038567    0.38007632  1.5183262   1.7148811   0.9541158\n",
      "  0.3594434   0.11363286]\n",
      "wvec: [ 0.88785243 -0.79433066  0.83022225  0.78897613  1.1329737  -1.7852131\n",
      "  1.9135057   0.50893855 -0.07947633 -2.1864004   0.39333153 -1.6843252\n",
      "  2.8249788  -1.3784927   0.66970193  4.1101203  -1.8050334  -0.4097362\n",
      "  1.854615   -1.6224682  -3.9795766   1.6430087  -0.99050075 -0.5331321\n",
      "  3.7172196   0.21821912  0.91679585  0.23741749 -4.110931    1.4240369\n",
      " -1.8175774  -2.1967895   2.369283    1.9470276   1.8389261   2.9744453\n",
      "  2.5899158   0.0915741   0.9428921   4.8478656   2.8966434  -0.81445855\n",
      "  0.19894971 -1.9366078   5.0983872   1.797193    1.5056374   0.481435\n",
      " -3.422971    1.2742809 ]\n",
      "wvec: [ 1.9093271   3.5993235  -2.1060312  -1.3701653   3.7165241  -1.7451384\n",
      " -2.6302512  -0.69035137 -1.279193   -3.2709908   2.7985287  -0.8071392\n",
      "  5.762425   -1.2996778  -1.8856791  -4.078497   -4.5447135  -2.2432444\n",
      "  0.2710475   0.8242331  -0.94575894  0.5017101   0.7603327  -2.8195128\n",
      " -2.8503644   1.781019    0.98180825  3.864216    2.2218995  -3.884911\n",
      "  0.26762074 -3.4196482   0.01753579  1.7722546   5.5977526  -1.9295844\n",
      "  2.807257   -2.533781    0.32211864  1.0640193   2.3224442   1.5067918\n",
      " -0.76914525  2.2627728   4.248701   -0.15823469  1.8352021   3.0427098\n",
      "  0.16502778  2.1917343 ]\n",
      "wvec: [ 3.4743156  -3.7146847   0.5481358   1.672032    1.8777416  -3.9769769\n",
      " -1.2658818   3.3025298   4.8983054  -5.3598638  -1.8102828   4.55135\n",
      "  1.7587659  -0.9220264  -0.83136237  3.5866668   3.1301658  -3.3851945\n",
      "  1.2546282   2.83516    -4.474767   -3.7256908   0.288744    2.9131389\n",
      " -2.5445845   2.4063091  -1.2839569  -2.5828114  -6.144157   -0.9358366\n",
      "  0.19982399 -2.2844908   0.55494416 -4.090529    0.02165406 -0.72134095\n",
      " -3.6751525   3.0017488   1.0175428   2.5965538   1.5005233  -1.8729568\n",
      " -4.599251    0.71001077 -2.8021672   4.306193    0.10504867  8.122803\n",
      "  4.517838    0.28625393]\n",
      "wvec: [ 0.09747349 -2.0637493   3.8953598  -5.449613    3.098801   -0.23738934\n",
      "  2.7498288  -1.5780543  -0.06853892  1.6280528  -7.7490673  -2.1214712\n",
      "  3.099681    3.117781    2.6668437   4.0483236  -5.1736937  -3.3160052\n",
      "  1.5451394  -0.16571216 -1.2262286  -0.15457201  2.713755   -0.6138246\n",
      "  7.182845    1.0432137   5.8832927   1.7372088   2.8795671  -1.1444818\n",
      "  2.6363347   2.0141578   0.36242983 -0.01092379 -0.14286463  0.40986115\n",
      " -1.8105042  -0.68052644  2.4587612  -1.4266462   1.7662009  -1.671752\n",
      " -0.18458381 -0.79854804  3.2551427   1.8362579  -2.1741457   2.869408\n",
      " -0.99122757  0.8555993 ]\n",
      "wvec: [ 1.1215198   0.7993391   0.22843608 -2.160645    0.6538255   0.6021061\n",
      "  0.1844606   1.5580077  -0.13983198  1.6659585  -0.9657      1.733775\n",
      " -0.1373138  -1.0730418   2.221077    1.2060871   1.5187298   1.322091\n",
      " -1.3082752   0.99831605  1.9624871  -0.02334558 -1.075241    0.07380199\n",
      "  1.2446281   0.2176221   0.65561223  0.54934186 -0.61095935 -0.01607278\n",
      "  0.29190567  0.18508062  1.0242956   0.16235904  2.0883827   0.46417227\n",
      " -0.32821986  1.23291     0.95217866 -0.34809652 -0.30681375  0.7393442\n",
      "  1.7928605   0.0570636   1.2824883   0.4036103  -0.05832006  0.9028465\n",
      " -1.3002254   1.082086  ]\n",
      "wvec: [-1.9024628   0.52465814 -2.0276148  -2.7716866   1.4322962  -2.3199363\n",
      " -0.8178245  -1.9550115   2.813393   -0.27018487  4.5702324  -1.9198816\n",
      "  1.5696756  -0.6739707  -1.7004774  -5.241645   -3.1796722   1.282675\n",
      " -0.7049025   1.217319    0.7312313  -0.6518665  -0.9064462   0.7058019\n",
      " -3.8860338   2.9427686   2.7294705  -0.6268329   0.53902763 -0.6974968\n",
      "  4.135625   -0.19438776  0.09628799  0.7086296   4.051538   -1.0286587\n",
      "  2.2047908  -2.9671938  -5.357528    0.02396253  1.6660749  -1.1826403\n",
      " -0.12400702  1.8741769  -1.2912644  -2.5543654   0.81952643 -1.0580825\n",
      " -0.12966281  0.32992983]\n",
      "wvec: [ 1.06168486e-01 -4.22313976e+00 -5.86366236e-01  1.61635841e-03\n",
      "  3.33660126e+00  3.45208359e+00 -7.10405231e-01  3.59776926e+00\n",
      " -3.05884391e-01  2.86163497e+00 -1.68095851e+00  7.56438911e-01\n",
      " -3.39603710e+00 -6.04276180e+00  1.20944309e+00  8.42349648e-01\n",
      " -5.06017387e-01  1.15956128e-01  2.08621073e+00  4.42298204e-01\n",
      "  1.80216229e+00 -1.02865648e+00 -5.69167519e+00  1.52147102e+00\n",
      "  2.95102239e+00  6.32928491e-01  1.02648365e+00 -5.88919401e-01\n",
      "  1.00201392e+00 -2.67713928e+00 -4.65943158e-01  7.69408703e-01\n",
      " -1.62942290e+00  2.39617062e+00  4.18235588e+00  1.87824881e+00\n",
      "  2.40684435e-01  9.27517295e-01  1.32670784e+00 -1.90556157e+00\n",
      "  1.41510224e+00  5.29519081e-01  2.99547052e+00  7.35925674e-01\n",
      "  1.53292251e+00  3.63743472e+00 -1.96556032e+00  2.23842931e+00\n",
      " -1.30895093e-01  2.57247353e+00]\n",
      "wvec: [-0.24382988  1.5777347   3.393736    1.03311     1.0683632   0.6366107\n",
      "  1.8619022   0.16980585 -1.275523   -0.42655492  0.34907484 -0.99841154\n",
      "  0.9524723   3.1640394   2.679835    1.4301037  -1.4942776  -1.1331767\n",
      " -0.5463017   2.4913006   0.4061109   1.8843179   0.1822601  -1.6946021\n",
      "  1.0987306  -2.3250847   0.46623453 -1.1711255  -1.360193   -0.4841549\n",
      "  0.25537732  0.52703774  1.1763278   0.11239862  1.395774    0.9210588\n",
      "  1.6879736  -0.42109627  1.3604666   1.7332162  -0.315498   -0.6526611\n",
      " -0.1743133  -1.038567    0.38007632  1.5183262   1.7148811   0.9541158\n",
      "  0.3594434   0.11363286]\n",
      "wvec: [ 3.2292     -0.2151858   1.1767884  -0.8283231   4.194563   -3.4215658\n",
      "  5.711827    1.7540876  -0.32773712  3.2292032  -2.1699245   2.2350745\n",
      "  1.9479544  -1.1891863   5.741619    2.6521266  -0.56258035  2.1129303\n",
      " -0.19973055 -1.7222937  -0.4611444   1.0465065  -2.9879854  -2.505585\n",
      "  7.652054    7.684763   -3.916804    3.2871132  -1.1020005   1.1442834\n",
      " -0.3758936   0.45149723  1.6484265   2.6366298   2.5965128   1.0046738\n",
      "  3.0630403   1.1203233   0.9736847   4.20678    -2.2556152   2.8237088\n",
      "  2.6855488  -3.1954412   6.279388    2.3480172  -2.9084027   2.0682652\n",
      " -1.1925809   6.757712  ]\n",
      "wvec: [-0.04592704  0.06480706 -0.5988447  -0.6608184   0.3785131   1.1440479\n",
      "  0.05332275  1.2706026  -0.1266708   0.7102547  -0.07772854  0.81541044\n",
      " -0.03368187 -1.0228463   0.5027258  -1.0495203   0.6672049  -0.23835768\n",
      "  0.28975534  0.27024698  0.91447675 -0.57552636 -0.05491778  0.41104326\n",
      "  0.02765665  0.17353421  0.63289964  0.4279627   0.3043215  -0.4835574\n",
      "  0.7513125  -0.18341558 -0.42875057 -0.1767174   0.8029682  -0.26063806\n",
      "  0.21410352  0.3836655  -0.69003654 -1.0385485  -0.1472115   0.2559312\n",
      " -0.20104693  0.86546206  0.5784685  -0.4392899  -0.5541171   1.0632995\n",
      " -0.4284697  -1.2570239 ]\n",
      "wvec: [-0.91447234 -0.27951857  1.1517961  -0.89875144  2.291544   -0.5166245\n",
      "  2.9339094   1.92142    -2.6902328  -2.9561415   1.9660342  -0.56479126\n",
      "  0.11154719 -1.1216751  -0.24468882  6.028402    0.6605593   1.6329616\n",
      "  1.32385    -3.2763023  -3.2670763  -0.10137635  1.0924532   0.9233831\n",
      "  1.1390047   0.80799586  1.1156524  -0.4855302  -1.4070641  -1.2909353\n",
      "  1.9724851   1.6599969   0.13947424  1.5560439   1.6971935   2.3314424\n",
      "  0.40281436 -0.32557064  2.02958     4.4206653   4.9930615  -1.5050371\n",
      "  1.2004455   0.76844954  2.1551769   1.743456    0.40600467 -0.27410826\n",
      " -1.8403231   0.5565823 ]\n",
      "wvec: [ 2.5252447   1.2873851  -0.59113014 -2.316803   -3.7253559  -0.49588677\n",
      "  2.2804852  -0.5199154   2.214568    2.3650374   0.46293244 -2.120859\n",
      "  0.46006536 -0.46217093 -4.4173927   3.7432878  -1.2138268   1.7455928\n",
      "  2.261568   -1.5410765   0.20620757  0.41018295 -0.93243897  1.723567\n",
      "  0.27145508  0.08921907 -1.0818775  -2.0059109  -0.9390184   0.12065753\n",
      " -3.218579   -4.20382     4.6578894   1.0480034   3.8063378   0.02857085\n",
      "  1.1814766  -1.6025653  -3.4811935   1.8660146   2.232851   -2.9542806\n",
      " -0.8198008   1.434674    3.19652     3.19228     1.7554266  -1.2228929\n",
      " -4.4748487  -1.1523428 ]\n",
      "wvec: [ 3.4743156  -3.7146847   0.5481358   1.672032    1.8777416  -3.9769769\n",
      " -1.2658818   3.3025298   4.8983054  -5.3598638  -1.8102828   4.55135\n",
      "  1.7587659  -0.9220264  -0.83136237  3.5866668   3.1301658  -3.3851945\n",
      "  1.2546282   2.83516    -4.474767   -3.7256908   0.288744    2.9131389\n",
      " -2.5445845   2.4063091  -1.2839569  -2.5828114  -6.144157   -0.9358366\n",
      "  0.19982399 -2.2844908   0.55494416 -4.090529    0.02165406 -0.72134095\n",
      " -3.6751525   3.0017488   1.0175428   2.5965538   1.5005233  -1.8729568\n",
      " -4.599251    0.71001077 -2.8021672   4.306193    0.10504867  8.122803\n",
      "  4.517838    0.28625393]\n",
      "wvec: [ -3.7043157    3.696106     4.0369606    6.0576873   -3.826663\n",
      "  -1.4335282   -4.3638997   -2.5766518    0.25193942  -1.7498202\n",
      "  -1.9965322    3.96744     -1.8137083    1.0980552    3.9405816\n",
      "  -1.3605785    3.1416607    1.861639     2.5409667    5.304666\n",
      "   3.8468924    3.5909166   -3.2290506   -0.23934738  -2.5783758\n",
      "  -0.92609864  -4.395808     0.5905163   -1.7559699   -2.8787804\n",
      "   4.423144    -3.7398043   -6.399274     3.8774974    0.12545122\n",
      "   2.4425025    4.8004804   -0.9372288   -2.1760697    3.471988\n",
      "  -4.539907   -10.955086     3.4873233   -5.249267     1.9988984\n",
      "  -4.2567296    0.12881833  -2.270183    -2.9240263    0.39028266]\n",
      "wvec: [ 0.81881994  0.34379318 -2.5974462  -0.54920846  1.7682586  -3.5079622\n",
      "  2.1199677   0.44573367  0.80435944 -2.0848255   2.0697079   2.8636615\n",
      " -2.2874036  -0.32330975  0.7778961   0.4881324  -0.8422965   0.30520943\n",
      " -1.5076973   2.5292077  -0.65450066 -1.545396    1.4821428  -0.47144693\n",
      "  0.33213222  2.8441932  -0.59823775 -4.580685   -0.06549549 -2.7374382\n",
      " -2.9227946   0.47711745  0.94402754 -0.442832   -0.94892263 -0.47525004\n",
      " -1.9730163  -2.875222    0.49184236 -2.630356    4.360905   -0.8648291\n",
      " -0.3382614  -5.0530367  -0.994174    5.017493    4.179835    1.1950756\n",
      "  1.8034973  -2.5717769 ]\n",
      "sent_vec: [ 23.20342427  11.18304479  33.53601605   6.23230331  36.32434635\n",
      " -27.78121804   9.1760886   12.96319614  -8.58489633 -21.95122364\n",
      " -18.33731769   2.86534931   6.39847891 -26.05844139  48.13167256\n",
      "  67.60502669 -28.15957479  -2.03472248   2.24583083  12.04289542\n",
      " -26.97792336  -8.13649849 -13.13845999   6.36237233   8.68909021\n",
      "   3.83848092 -32.77569938 -43.07059518 -38.25128001 -23.2699187\n",
      "   0.44813952  -4.43850429  -4.25008097  30.81040476  51.6274471\n",
      "   6.2318393   22.39625268 -16.72352051  -7.0046855   55.39502413\n",
      "  21.96373127 -66.07323271  18.4168708  -33.22168766  43.40413419\n",
      "  61.73796393  42.41396315  39.32888898 -22.6420009   44.13769773]\n",
      "avg_vec: [ 0.48340467  0.2329801   0.698667    0.12983965  0.75675722 -0.57877538\n",
      "  0.19116851  0.27006659 -0.17885201 -0.45731716 -0.38202745  0.05969478\n",
      "  0.13330164 -0.5428842   1.00274318  1.40843806 -0.58665781 -0.04239005\n",
      "  0.04678814  0.25089365 -0.56204007 -0.16951039 -0.27371792  0.13254942\n",
      "  0.18102271  0.07996835 -0.68282707 -0.89730407 -0.79690167 -0.48478997\n",
      "  0.00933624 -0.09246884 -0.08854335  0.64188343  1.07557181  0.12982999\n",
      "  0.4665886  -0.34840668 -0.14593095  1.154063    0.45757773 -1.37652568\n",
      "  0.38368481 -0.69211849  0.9042528   1.28620758  0.88362423  0.81935185\n",
      " -0.47170835  0.91953537]\n",
      "*******************************************************************\n"
     ]
    }
   ],
   "source": [
    "avg_vec = [] #List to store all the avg w2vec's \n",
    "for sent in final_string[0:1]:\n",
    "    cnt = 0 #to count no of words in each reviews\n",
    "    sent_vec = np.zeros(50) #Initializing with zeroes\n",
    "    print(\"sent:\",sent) \n",
    "    for word in sent:\n",
    "        try:\n",
    "            wvec = w2v_model.wv[word] #Vector of each using w2v model\n",
    "            print(\"wvec:\",wvec)\n",
    "            sent_vec += wvec #Adding the vectors \n",
    "            cnt += 1\n",
    "        except: \n",
    "            pass #When the word is not in the dictionary then do nothing \n",
    "    print(\"sent_vec:\",sent_vec)    \n",
    "    a_vec =sent_vec / cnt #Taking average of vectors sum of the particular review\n",
    "    print(\"avg_vec:\",a_vec)\n",
    "    avg_vec.append(a_vec) #Storing the avg w2vec's for each review\n",
    "    print(\"*******************************************************************\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 136.30994200706482\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "avg_vec = [] #List to store all the avg w2vec's \n",
    "for sent in final_string:\n",
    "    cnt = 0 #to count no of words in each reviews\n",
    "    sent_vec = np.zeros(50) #Initializing with zeroes\n",
    "    for word in sent:\n",
    "        try:\n",
    "            wvec = w2v_model.wv[word] #Vector of each using w2v model\n",
    "            sent_vec += wvec #Adding the vectors \n",
    "            cnt += 1\n",
    "        except: \n",
    "            pass #When the word is not in the dictionary then do nothing \n",
    "    a_vec =sent_vec / cnt #Taking average of vectors sum of the particular review\n",
    "    avg_vec.append(a_vec) #Storing the avg w2vec's for each review\n",
    "    #print(\"*******************************************************************\")\n",
    "print(\"Total time taken:\",time()-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf W2Vec\n",
    "* Another way to covert sentence into vectors\n",
    "* Take weighted sum of the vectors divided by the sum of all the tfidf's \n",
    "<br>i.e. (tfidf(word) x w2v(word))/sum(tfidf's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "tfidf_w2vecs = []\n",
    "review = 0\n",
    "for sent in final_string:\n",
    "    cnt = 0 \n",
    "    weighted_sum  = 0\n",
    "    sent_vec = np.zeros(50)\n",
    "    for word in sent:\n",
    "        try:\n",
    "            wvec = w2v_model.wv[word]\n",
    "#             print(\"w2vec:\",wvec)\n",
    "            tfidf = tfidf_vec[review,features.index(word)]\n",
    "#             print(tfidf)\n",
    "            sent_vec += (wvec * tfidf)\n",
    "            weighted_sum += tfidf\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= weighted_sum\n",
    "    tfidf_w2vecs.append(sent_vec)\n",
    "    review += 1\n",
    "print(\"Total time taken:\",time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tfidf_w2vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tfidf_w2vecs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_w2vecs[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE on Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uni-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from time import time\n",
    "\n",
    "sample_features = uni_gram_vectors\n",
    "# sample_features = df\n",
    "sample_class = df['Score']\n",
    "sample_class = sample_class[:,np.newaxis]\n",
    "print(sample_features.shape,sample_class.shape)\n",
    "model = TSNE(n_components=2,random_state=0,perplexity=30)\n",
    "# print(sample_features,sample_class)\n",
    "\n",
    "t0 = time()\n",
    "embedded_data = model.fit_transform(sample_features.todense())\n",
    "print(\"TSNE done in %0.3fs.\" % (time() - t0)) \n",
    "# print(embedded_data.shape,sample_class.shape)\n",
    "final_data = np.concatenate((embedded_data,sample_class),axis=1)\n",
    "print(final_data.shape)\n",
    "newdf = pd.DataFrame(data=final_data,columns=[\"Dim1\",\"Dim2\",\"Class\"])\n",
    "\n",
    "sns.FacetGrid(newdf,hue=\"Class\",size=6).map(plt.scatter,\"Dim1\",\"Dim2\").add_legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from time import time\n",
    "\n",
    "sample_features = bi_gram_vectors\n",
    "# sample_features = df\n",
    "sample_class = df['Score']\n",
    "sample_class = sample_class[:,np.newaxis]\n",
    "print(sample_features.shape,sample_class.shape)\n",
    "model = TSNE(n_components=2,random_state=0,perplexity=30)\n",
    "# print(sample_features,sample_class)\n",
    "\n",
    "t0 = time()\n",
    "embedded_data = model.fit_transform(sample_features.todense())\n",
    "print(\"TSNE done in %0.3fs.\" % (time() - t0)) \n",
    "\n",
    "final_data = np.concatenate((embedded_data,sample_class),axis=1)\n",
    "print(final_data.shape)\n",
    "newdf = pd.DataFrame(data=final_data,columns=[\"Dim1\",\"Dim2\",\"Class\"])\n",
    "\n",
    "sns.FacetGrid(newdf,hue=\"Class\",size=6).map(plt.scatter,\"Dim1\",\"Dim2\").add_legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from time import time\n",
    "\n",
    "sample_features = tfidf_vec\n",
    "# sample_features = df\n",
    "sample_class = df['Score']\n",
    "sample_class = sample_class[:,np.newaxis]\n",
    "print(sample_features.shape,sample_class.shape)\n",
    "model = TSNE(n_components=2,random_state=0,perplexity=30)\n",
    "# print(sample_features,sample_class)\n",
    "\n",
    "t0 = time()\n",
    "embedded_data = model.fit_transform(sample_features.todense())\n",
    "print(\"TSNE done in %0.3fs.\" % (time() - t0)) \n",
    "\n",
    "final_data = np.concatenate((embedded_data,sample_class),axis=1)\n",
    "print(final_data.shape)\n",
    "newdf = pd.DataFrame(data=final_data,columns=[\"Dim1\",\"Dim2\",\"Class\"])\n",
    "\n",
    "sns.FacetGrid(newdf,hue=\"Class\",size=6).map(plt.scatter,\"Dim1\",\"Dim2\").add_legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### avg-w2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from time import time\n",
    "\n",
    "sample_features = avg_vec[:20]\n",
    "# sample_features = df\n",
    "sample_class = df['Score'][:20]\n",
    "sample_class = sample_class[:,np.newaxis]\n",
    "print(sample_features.shape,sample_class.shape)\n",
    "model = TSNE(n_components=2,random_state=0,perplexity=30)\n",
    "# print(sample_features,sample_class)\n",
    "\n",
    "t0 = time()\n",
    "embedded_data = model.fit_transform(sample_features.todense())\n",
    "print(\"TSNE done in %0.3fs.\" % (time() - t0)) \n",
    "\n",
    "final_data = np.concatenate((embedded_data,sample_class),axis=1)\n",
    "print(final_data.shape)\n",
    "newdf = pd.DataFrame(data=final_data,columns=[\"Dim1\",\"Dim2\",\"Class\"])\n",
    "\n",
    "sns.FacetGrid(newdf,hue=\"Class\",size=6).map(plt.scatter,\"Dim1\",\"Dim2\").add_legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf w2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from time import time\n",
    "\n",
    "sample_features = tfidf_w2vecs[:20]\n",
    "# sample_features = df\n",
    "sample_class = df['Score'][:20]\n",
    "sample_class = sample_class[:,np.newaxis]\n",
    "print(sample_features.shape,sample_class.shape)\n",
    "model = TSNE(n_components=2,random_state=0,perplexity=30)\n",
    "# print(sample_features,sample_class)\n",
    "\n",
    "t0 = time()\n",
    "embedded_data = model.fit_transform(sample_features.todense())\n",
    "print(\"TSNE done in %0.3fs.\" % (time() - t0)) \n",
    "\n",
    "final_data = np.concatenate((embedded_data,sample_class),axis=1)\n",
    "print(final_data.shape)\n",
    "newdf = pd.DataFrame(data=final_data,columns=[\"Dim1\",\"Dim2\",\"Class\"])\n",
    "\n",
    "sns.FacetGrid(newdf,hue=\"Class\",size=6).map(plt.scatter,\"Dim1\",\"Dim2\").add_legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "(1) http://blog.aylien.com/10-common-nlp-terms-explained-for-the-text/<br>\n",
    "(2) https://en.wikipedia.org/<br>\n",
    "(3) https://buhrmann.github.io/tfidf-analysis.html<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
